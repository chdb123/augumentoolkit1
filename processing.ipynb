{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Augmentool\n",
    "\n",
    "This notebook is where you generate all your data.\n",
    "\n",
    "Augmentool is meant to allow instruct-tuned models to learn from books, even using themselves to generate new data through a sort-of bootstrapping method. It is meant to stop model creators from having to work as data annotators, and not actual model trainers. It is meant to allow anyone to make their own high-quality dataset with thousands of entries.\n",
    "\n",
    "### Here are some ways you can adapt this notebook to your use case, along with a brief description of how to do so, arranged in increasing order of difficulty:\n",
    "\n",
    "1. ***Change the source texts used to generate training data.*** You can do this in the cell right below this one. **IMPORTANT** the filenames of these should be formatted in a specific way, since the filenames are used as part of the prompts and in at least one regex. You need to have them be like: `[textname], by authorname`. You can also include the publication date after the author name if you want, but note that this will tend to bias most of the characters to live in the era of the textbook, which may or may not be what you want.\n",
    "\n",
    "2. ***Change the personalities of the characters generated.*** Currently, when generating characters for the multiturn conversation step, three randomly-selected traits are appended to the \"special instructions\" set of the prompt to constrain what kind of character is generated by the model. Depending on what kind of model you want to make, or even just if your preferences vary, then you will probably want to modify this a bit. You can do so in `./generation_functions/special_instructions.py`. A more in-depth description of the trait-axis system that I (over)thought up is available in the comments of that file.\n",
    "\n",
    "3. ***Change the constants.*** There are a few constant values in this notebook, and in `./generation_functions/constant_values.py`. These constants are tested, but if your usecase requires special settings (e.g., you want to make conversations from more permutations of existing questions; or you think the character counts for the \"duplicate question/answer\" validation functions are too restrictive) then feel free to change the related setting. The most intuitive and least-likely-to-break-anything settings to change are rearrangements_to_take and double_check_counter. Beyond that... you'll need to figure out what the function does before changing it if you expect it to run.\n",
    "\n",
    "4. ***Change the model.*** This is as simple as switching the LOGICAL_MODEL parameter out for another one, but your mileage may vary, significantly. You will also have to adjust RoPE scaling for non-llama 2 models -- e.g., if you're using Mixtral, don't leave `rope_freq_scale=0.33`, which 3xes the context (you do not need 96k context, only 12k).\n",
    "\n",
    "5. ***Change the examples.*** If you change the examples you can completely overhaul what this notebook does, but this requires a lot of prompting skill and possibly huge amounts of time to get it working again (source: most of my last three months were spent prompting, and most of this prompting was spent on the examples). Unless you want to convert this notebook from question-and-answer generation to some completely other task, I'd recommend changing only the conversation generation prompts -- they're a bit less finnicky, and if you just want to change the kind of characters generated (maybe you want a different writing style) that's where you'd find the differences.\n",
    "\n",
    "## Quickstart:\n",
    "\n",
    "- Get this notebook and the other repo code onto a machine with the power to run Airoboros-l2-70b-3.1.2.Q4_K_M\n",
    "- Put the model into ./logical_models (relative to this notebook). \n",
    "- Run all the cells below and watch as the notebook generates questions, answers, and conversations based on Principles of Chemistry, Simple Sabotage, and Introduction to Philosophy.\n",
    "\n",
    "If you want to add your own texts, follow the instructions in list item #1 above.\n",
    "\n",
    "### Note: this notebook makes roughly 1/3 characters generated to be NSFW by default. You will want to follow point #2 above to change that if you want something cleaner. Or use \"Assistant mode\" which makes all the characters used be your typical sanitized \"As an AI language model\". \n",
    "Notice: Assistant mode is not fully implemented yet.\n",
    "\n",
    "## Why is it writing so many files?\n",
    "\n",
    "This notebook writes the final questions generated, the revisions of those questions, and the final multiturn conversations, to files. But it also writes the output of every single prompt to a unique file in a folder named for the prompt it's a part of (to a unique file whose filename is a uuid). Why all the writing? Taking inspiration from Jon Durbin's cinematika, this notebook records output information so that, in the future, possibly, a model can be finetuned specifically for running as the logical model behind the notebook. Writing each step down ensures that a dataset is made and outputs are not wasted. If a model is ever built, what'll probably be done is a regex and other code will be used to determine which runs (identified by the same uuid across folders) ended successfully, and these will make up the dataset. DPO might also be done on steps that failed vs steps that succeeded.\n",
    "\n",
    "The folders you want to look out for, by default, are named `qatuples_raw`, `qatuples_revised`, and `multi_turn_convs`.\n",
    "\n",
    "## Known limitations:\n",
    "\n",
    "Multi-turn conversations sometimes have impersonation (ie, one character will describe what another character does in their own message). This only happens sometimes from my testing, and is quite possibly easily fixable by creating a prompt that takes conversations with potential impersonation and rewrites them to have none. I merely have not done this yet.\n",
    "\n",
    "Multi-turn conversations can have the primary character ask if the secondary character needs anything else in a repetitive way. So for instance, the primary character might end with \"Do you need anything else?\" twice or thrice in a row. I am unsure whether this is a quirk of the model or the notebook, either way it should be easily fixable enough with a prompt (+ a regex that checks the end of statements, so that the prompt isn't called on things that are fine).\n",
    "\n",
    "Spelling mistakes -- I had to use RoPE to boost the ctx quite high, and I think this is causing the model to (VERY rarely) misspell things. This happens maybe one in a dozen outputs, maybe less. Models with higher ctx, e.g., Mixtral, probably won't suffer from this problem.\n",
    "\n",
    "Numbers -- I've found the model missing zeroes occasionally when spelling out dates. Unsure if this is a llama issue, an Airoboros issue, or a notebook/prompting issue.\n",
    "\n",
    "Sensitive to text differences -- I've tested this on a few texts, but I will say that depending on the book you are using, and how it's written, what you get with the default Augmentool will vary significantly. This can be unpredictable: for instance, this notebook really struggles with H.G. Wells' \"A Short History of the World\" but is mostly fine with \"Principles of Chemistry\" despite them both being quite old, factual texts. If you try this on a text you like and it doesn't work, here's the process to debug it: take some times it failed (the notebook saves prompt outputs at each step so you can find where it went stupid), and manually turn it into a few-shot example for the step that went bad, except fix it yourself. This should make the notebook less inclined to commit the same error. Then run it again, and if there's a new problem, fix it the same way.\n",
    "\n",
    "Other limitations -- I've listed the major ones but I'm sure there are a handful I'm forgetting.\n",
    "\n",
    "I'm just one developer with finite time -- feel free to address any of these issues yourself! I'm happy to give prompting pointers if you ask on the repo or on Discord (I'm @Heralax over there). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE NOTEBOOK SETTINGS AND CONSTANTS (some script file constants are in generation_functions/constants.py)\n",
    "\n",
    "# Put your desired quant of your desired model in the relevant directories\n",
    "\n",
    "\n",
    "# \"./logical_model/airoboros-l2-70b-3.1.2.Q4_K_M.gguf\"\n",
    "\n",
    "LOGICAL_MODEL = \"./logical_model/flatorcamaid-13b-v0.2.Q8_0.gguf\" # model used for decision-making and base question generation (should be \"smart\")\n",
    "RAM_IS_LIMITED = True # change this to false if you can fit both models on your GPU at once\n",
    "ASSISTANT_MODE = False # change to true if you want all conversations to be with an \"AI language model\" and not characters. Useful for more professional usecases. Currently TODO.\n",
    "DOUBLE_CHECK_COUNTER = 3 # Set to 1 to check outputs only once; set to 2 to check twice; set to 3 to check thrice, etc. Set to 0 to break everything in vet_question_loop() and elsewhere. Set to -1 and cause the universe to implode?\n",
    "\n",
    "REARRANGEMENTS_TO_TAKE = 3 # How many of the possible permutations of tuples in a group to take and make multiturn convs out of. Adjust higher to get more data out of less text, but it might be a bit repetitive. NOTE your eval loss will be basically worthless if you aren't careful with how you shuffle your dataset when you're about to train.\n",
    "\n",
    "source_texts = [\n",
    "    \"Principles of Chemistry, by Demitry Mendeleev, published 1897.txt\",\n",
    "    \"Simple Sabotage, by the Office of Strategic Services, published 1944.txt\",\n",
    "    \"Introduction to Philosophy, by George Stuart Fullerton.txt\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Gryphe/MythoMax-L2-13b\") # It doesn't matter what model goes here as long as it is sentencepiece\n",
    "\n",
    "def sentence_chunking_algorithm(file_path, tokenizer, max_token_length=400):\n",
    "    \"\"\"\n",
    "    This function takes a plaintext file and chunks it into sentences.\n",
    "    \n",
    "    :param file_path: Path to the plaintext file\n",
    "    :param tokenizer: SentencePiece tokenizer\n",
    "    :param max_token_length: The maximum token length for a chunk of sentences\n",
    "    :return: List of sentence chunks with source text information\n",
    "    \"\"\"\n",
    "    sentence_chunks_with_source = []\n",
    "    current_chunk = []\n",
    "    token_count = 0\n",
    "    source_name = file_path.replace(\".txt\",\"\")\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Remove Gutenberg header and footer\n",
    "    content = re.sub(r'^.*?START OF (THIS|THE) PROJECT GUTENBERG EBOOK.*$\\n', '', content, flags=re.MULTILINE)\n",
    "    content = re.sub(r'^.*?END OF (THIS|THE) PROJECT GUTENBERG EBOOK.*$\\n', '', content, flags=re.MULTILINE)\n",
    "\n",
    "    sentences = sent_tokenize(content)\n",
    "\n",
    "    for sentence in tqdm(sentences, desc=f\"Processing {file_path}\"):\n",
    "        sentence_token_count = len(tokenizer.encode(sentence))\n",
    "\n",
    "        if token_count + sentence_token_count <= max_token_length:\n",
    "            current_chunk.append(sentence)\n",
    "            token_count += sentence_token_count\n",
    "        else:\n",
    "            sentence_chunks_with_source.append((' '.join(current_chunk), source_name))\n",
    "            current_chunk = [sentence]\n",
    "            token_count = sentence_token_count\n",
    "\n",
    "    # Add the last chunk if it exists\n",
    "    if current_chunk:\n",
    "        sentence_chunks_with_source.append((' '.join(current_chunk), source_name))\n",
    "\n",
    "    return sentence_chunks_with_source\n",
    "\n",
    "\n",
    "\n",
    "sentence_chunks = []\n",
    "for source_text in source_texts:\n",
    "    sentence_chunks += sentence_chunking_algorithm(source_text, tokenizer)\n",
    "\n",
    "def fix_text(to_replace_arr, text):\n",
    "    for startup in to_replace_arr:\n",
    "        text = text.replace(startup[0], startup[1])\n",
    "    return text\n",
    "\n",
    "conversions = [(\"\\n\",\" \"), (\"  \", \" \")]\n",
    "\n",
    "paragraphs_processed = [(fix_text(conversions, seq[0]), seq[1]) for seq in sentence_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paragraphs_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs_processed[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rp_llm = Llama(model_path=RP_MODEL,n_ctx=4096,n_gpu_layers=100) # load the RP llp and offload everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_llm = Llama(model_path=LOGICAL_MODEL,n_gqa=8,offload_kqv=True,n_ctx=12000,rope_freq_scale=0.33,n_gpu_layers=100,verbose=False) # load the logical LLM and offload everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "print_grammar: error printing grammar: malformed rule, does not end with LLAMA_GRETYPE_END: 2\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root ::= text-analysis answer-breakdown accuracy-check final-judgment \n",
      "text-analysis ::= [#] [#] [#] [ ] [T] [e] [x] [t] [ ] [A] [n] [a] [l] [y] [s] [i] [s] [:] [<U+000A>] identify-key-info categorize-info-type \n",
      "answer-breakdown ::= [#] [#] [#] [ ] [A] [n] [s] [w] [e] [r] [ ] [B] [r] [e] [a] [k] [d] [o] [w] [n] [:] [<U+000A>] dissect-answer identify-answer-type \n",
      "accuracy-check ::= [#] [#] [#] [ ] [A] [c] [c] [u] [r] [a] [c] [y] [ ] [C] [h] [e] [c] [k] [:] [<U+000A>] direct-comparison inference-and-contextual-alignment \n",
      "final-judgment ::= [#] [#] [#] [ ] [F] [i] [n] [a] [l] [ ] [J] [u] [d] [g] [m] [e] [n] [t] [:] [<U+000A>] comprehensive-assessment overall-accuracy-determination \n",
      "identify-key-info ::= [#] [#] [#] [#] [ ] [I] [d] [e] [n] [t] [i] [f] [y] [ ] [K] [e] [y] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [:] [ ] text-info-detail [<U+000A>] \n",
      "categorize-info-type ::= [#] [#] [#] [#] [ ] [C] [a] [t] [e] [g] [o] [r] [i] [z] [e] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [ ] [T] [y] [p] [e] [:] [ ] info-type-detail [<U+000A>] [<U+000A>] \n",
      "text-info-detail ::= text-info-detail_24 \n",
      "info-type-detail ::= info-type-detail_25 \n",
      "dissect-answer ::= [#] [#] [#] [#] [ ] [D] [i] [s] [s] [e] [c] [t] [ ] [t] [h] [e] [ ] [A] [n] [s] [w] [e] [r] [:] [ ] answer-detail [<U+000A>] \n",
      "identify-answer-type ::= [#] [#] [#] [#] [ ] [I] [d] [e] [n] [t] [i] [f] [y] [ ] [A] [n] [s] [w] [e] [r] [ ] [T] [y] [p] [e] [:] [ ] answer-type-detail [<U+000A>] [<U+000A>] \n",
      "answer-detail ::= answer-detail_26 \n",
      "answer-type-detail ::= answer-type-detail_27 \n",
      "direct-comparison ::= [#] [#] [#] [#] [ ] [D] [i] [r] [e] [c] [t] [ ] [C] [o] [m] [p] [a] [r] [i] [s] [o] [n] [ ] [f] [o] [r] [ ] [F] [a] [c] [t] [u] [a] [l] [ ] [A] [c] [c] [u] [r] [a] [c] [y] [:] [<U+000A>] comparison-points \n",
      "inference-and-contextual-alignment ::= [#] [#] [#] [#] [ ] [I] [n] [f] [e] [r] [e] [n] [c] [e] [ ] [a] [n] [d] [ ] [C] [o] [n] [t] [e] [x] [t] [u] [a] [l] [ ] [A] [l] [i] [g] [n] [m] [e] [n] [t] [:] [ ] contextual-alignment-detail [<U+000A>] [<U+000A>] \n",
      "comparison-points ::= comparison-points_17 \n",
      "bullet-point ::= [ ] [ ] [-] [ ] comparison-point-detail [<U+000A>] \n",
      "comparison-points_17 ::= bullet-point comparison-points_17 | bullet-point \n",
      "comparison-point-detail ::= comparison-point-detail_28 \n",
      "contextual-alignment-detail ::= contextual-alignment-detail_29 \n",
      "comprehensive-assessment ::= [#] [#] [#] [#] [ ] [C] [o] [m] [p] [r] [e] [h] [e] [n] [s] [i] [v] [e] [ ] [A] [s] [s] [e] [s] [s] [m] [e] [n] [t] [:] [ ] assessment-detail [<U+000A>] \n",
      "overall-accuracy-determination ::= [#] [#] [#] [#] [ ] [O] [v] [e] [r] [a] [l] [l] [ ] [A] [c] [c] [u] [r] [a] [c] [y] [ ] [D] [e] [t] [e] [r] [m] [i] [n] [a] [t] [i] [o] [n] [:] [ ] accuracy-detail [<U+000A>] \n",
      "assessment-detail ::= assessment-detail_30 \n",
      "accuracy-detail ::= accuracy-detail_31 \n",
      "text-info-detail_24 ::= [^<U+000A>] text-info-detail_24 | [^<U+000A>] \n",
      "info-type-detail_25 ::= [^<U+000A>] info-type-detail_25 | [^<U+000A>] \n",
      "answer-detail_26 ::= [^<U+000A>] answer-detail_26 | [^<U+000A>] \n",
      "answer-type-detail_27 ::= [^<U+000A>] answer-type-detail_27 | [^<U+000A>] \n",
      "comparison-point-detail_28 ::= [^<U+000A>] comparison-point-detail_28 | [^<U+000A>] \n",
      "contextual-alignment-detail_29 ::= [^<U+000A>] contextual-alignment-detail_29 | [^<U+000A>] \n",
      "assessment-detail_30 ::= [^<U+000A>] assessment-detail_30 | [^<U+000A>] \n",
      "accuracy-detail_31 ::= [^<U+000A>] accuracy-detail_31 | [^<U+000A>] \n",
      "root ::= analyze-step understand-step identify-step plan-revised-step [<U+000A>] \n",
      "analyze-step ::= [S] [t] [e] [p] [ ] analyze-step_5 [0-9] [.] [ ] [A] [n] [a] [l] [y] [z] [e] [ ] [t] [h] [e] [ ] [T] [e] [x] [t] [:] analyze-step_6 [<U+000A>] \n",
      "understand-step ::= [S] [t] [e] [p] [ ] understand-step_7 [0-9] [.] [ ] [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] [ ] [t] [h] [e] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [:] understand-step_8 [<U+000A>] \n",
      "identify-step ::= [S] [t] [e] [p] [ ] identify-step_9 [0-9] [.] [ ] [I] [d] [e] [n] [t] [i] [f] [y] [ ] [F] [l] [a] [w] [e] [d] [ ] [P] [a] [r] [t] [ ] [o] [f] [ ] [t] [h] [e] [ ] [A] [n] [s] [w] [e] [r] [:] identify-step_10 [<U+000A>] \n",
      "plan-revised-step ::= [S] [t] [e] [p] [ ] plan-revised-step_11 [0-9] [.] [ ] [P] [l] [a] [n] [ ] [R] [e] [v] [i] [s] [e] [d] [ ] [A] [n] [s] [w] [e] [r] [:] plan-revised-step_12 [<U+000A>] \n",
      "analyze-step_5 ::= [0-9] | \n",
      "analyze-step_6 ::= [^<U+000A>] analyze-step_6 | [^<U+000A>] \n",
      "understand-step_7 ::= [0-9] | \n",
      "understand-step_8 ::= [^<U+000A>] understand-step_8 | [^<U+000A>] \n",
      "identify-step_9 ::= [0-9] | \n",
      "identify-step_10 ::= [^<U+000A>] identify-step_10 | [^<U+000A>] \n",
      "plan-revised-step_11 ::= [0-9] | \n",
      "plan-revised-step_12 ::= [^<U+000A>] plan-revised-step_12 | [^<U+000A>] \n",
      "root ::= deep-analysis [<U+000A>] comprehensive-understanding [<U+000A>] targeted-comparison [<U+000A>] identification-of-extraneous-info [<U+000A>] final-judgment \n",
      "deep-analysis ::= [#] [#] [#] [ ] [D] [e] [e] [p] [ ] [A] [n] [a] [l] [y] [s] [i] [s] [ ] [o] [f] [ ] [t] [h] [e] [ ] [T] [e] [x] [t] [:] [<U+000A>] content-scope-and-detail type-of-information \n",
      "comprehensive-understanding ::= [#] [#] [#] [ ] [C] [o] [m] [p] [r] [e] [h] [e] [n] [s] [i] [v] [e] [ ] [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] [i] [n] [g] [ ] [o] [f] [ ] [t] [h] [e] [ ] [A] [n] [s] [w] [e] [r] [:] [<U+000A>] key-components-identification depth-of-explanation \n",
      "targeted-comparison ::= [#] [#] [#] [ ] [T] [a] [r] [g] [e] [t] [e] [d] [ ] [C] [o] [m] [p] [a] [r] [i] [s] [o] [n] [ ] [o] [f] [ ] [A] [n] [s] [w] [e] [r] [ ] [w] [i] [t] [h] [ ] [T] [e] [x] [t] [:] [<U+000A>] content-alignment depth-alignment \n",
      "identification-of-extraneous-info ::= [#] [#] [#] [ ] [I] [d] [e] [n] [t] [i] [f] [i] [c] [a] [t] [i] [o] [n] [ ] [o] [f] [ ] [E] [x] [t] [r] [a] [n] [e] [o] [u] [s] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [:] [<U+000A>] spotting-additional-details assessing-impact \n",
      "final-judgment ::= [#] [#] [#] [ ] [F] [i] [n] [a] [l] [ ] [J] [u] [d] [g] [m] [e] [n] [t] [ ] [o] [n] [ ] [A] [n] [s] [w] [e] [r] [ ] [R] [e] [l] [e] [v] [a] [n] [c] [e] [:] [<U+000A>] relevance-assessment explanation-of-judgment \n",
      "content-scope-and-detail ::= [#] [#] [#] [#] [ ] [C] [o] [n] [t] [e] [n] [t] [ ] [S] [c] [o] [p] [e] [ ] [a] [n] [d] [ ] [D] [e] [t] [a] [i] [l] [:] [ ] text-detail [<U+000A>] \n",
      "type-of-information ::= [#] [#] [#] [#] [ ] [T] [y] [p] [e] [ ] [o] [f] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [:] [ ] info-type [<U+000A>] \n",
      "text-detail ::= text-detail_26 \n",
      "info-type ::= info-type_27 \n",
      "key-components-identification ::= [#] [#] [#] [#] [ ] [K] [e] [y] [ ] [C] [o] [m] [p] [o] [n] [e] [n] [t] [s] [ ] [I] [d] [e] [n] [t] [i] [f] [i] [c] [a] [t] [i] [o] [n] [:] [ ] components-detail [<U+000A>] \n",
      "depth-of-explanation ::= [#] [#] [#] [#] [ ] [D] [e] [p] [t] [h] [ ] [o] [f] [ ] [E] [x] [p] [l] [a] [n] [a] [t] [i] [o] [n] [:] [ ] explanation-detail [<U+000A>] \n",
      "components-detail ::= components-detail_28 \n",
      "explanation-detail ::= explanation-detail_29 \n",
      "content-alignment ::= [#] [#] [#] [#] [ ] [C] [o] [n] [t] [e] [n] [t] [ ] [A] [l] [i] [g] [n] [m] [e] [n] [t] [:] [ ] alignment-detail [<U+000A>] \n",
      "depth-alignment ::= [#] [#] [#] [#] [ ] [D] [e] [p] [t] [h] [ ] [A] [l] [i] [g] [n] [m] [e] [n] [t] [:] [ ] depth-detail [<U+000A>] \n",
      "alignment-detail ::= alignment-detail_30 \n",
      "depth-detail ::= depth-detail_31 \n",
      "spotting-additional-details ::= [#] [#] [#] [#] [ ] [S] [p] [o] [t] [t] [i] [n] [g] [ ] [A] [d] [d] [i] [t] [i] [o] [n] [a] [l] [ ] [D] [e] [t] [a] [i] [l] [s] [:] [ ] additional-details [<U+000A>] \n",
      "assessing-impact ::= [#] [#] [#] [#] [ ] [A] [s] [s] [e] [s] [s] [i] [n] [g] [ ] [I] [m] [p] [a] [c] [t] [ ] [o] [f] [ ] [A] [d] [d] [i] [t] [i] [o] [n] [a] [l] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [:] [ ] impact-assessment [<U+000A>] \n",
      "additional-details ::= additional-details_32 \n",
      "impact-assessment ::= impact-assessment_33 \n",
      "relevance-assessment ::= [#] [#] [#] [#] [ ] [R] [e] [l] [e] [v] [a] [n] [c] [e] [ ] [A] [s] [s] [e] [s] [s] [m] [e] [n] [t] [:] [ ] relevance-detail [<U+000A>] \n",
      "explanation-of-judgment ::= [#] [#] [#] [#] [ ] [E] [x] [p] [l] [a] [n] [a] [t] [i] [o] [n] [ ] [o] [f] [ ] [J] [u] [d] [g] [m] [e] [n] [t] [:] [ ] judgment-detail [<U+000A>] \n",
      "relevance-detail ::= relevance-detail_34 \n",
      "judgment-detail ::= judgment-detail_35 \n",
      "text-detail_26 ::= [^<U+000A>] text-detail_26 | [^<U+000A>] \n",
      "info-type_27 ::= [^<U+000A>] info-type_27 | [^<U+000A>] \n",
      "components-detail_28 ::= [^<U+000A>] components-detail_28 | [^<U+000A>] \n",
      "explanation-detail_29 ::= [^<U+000A>] explanation-detail_29 | [^<U+000A>] \n",
      "alignment-detail_30 ::= [^<U+000A>] alignment-detail_30 | [^<U+000A>] \n",
      "depth-detail_31 ::= [^<U+000A>] depth-detail_31 | [^<U+000A>] \n",
      "additional-details_32 ::= [^<U+000A>] additional-details_32 | [^<U+000A>] \n",
      "impact-assessment_33 ::= [^<U+000A>] impact-assessment_33 | [^<U+000A>] \n",
      "relevance-detail_34 ::= [^<U+000A>] relevance-detail_34 | [^<U+000A>] \n",
      "judgment-detail_35 ::= [^<U+000A>] judgment-detail_35 | [^<U+000A>] \n",
      "root ::= name [<U+000A>] [T] [r] [a] [i] [t] [s] [:] [ ] traits [<U+000A>] [<U+000A>] [D] [i] [a] [l] [o] [g] [u] [e] [ ] [E] [x] [a] [m] [p] [l] [e] [s] [:] dialogue-examples \n",
      "name ::= name_4 \n",
      "traits ::= trait trait trait trait trait trait trait trait trait trait trait trait traits_6 traits_7 traits_8 traits_9 traits_10 traits_11 traits_12 traits_13 \n",
      "dialogue-examples ::= history personality \n",
      "name_4 ::= [^<U+000A> ] name_4 | [^<U+000A> ] \n",
      "trait ::= [A-Z] trait_14 [,] [ ] \n",
      "traits_6 ::= trait | \n",
      "traits_7 ::= trait | \n",
      "traits_8 ::= trait | \n",
      "traits_9 ::= trait | \n",
      "traits_10 ::= trait | \n",
      "traits_11 ::= trait | \n",
      "traits_12 ::= trait | \n",
      "traits_13 ::= trait | \n",
      "trait_14 ::= [a-z '] trait_14 | [a-z '] \n",
      "history ::= [<U+000A>] [S] [t] [r] [a] [n] [g] [e] [r] [:] [ ] [\"] [W] [h] [a] [t] ['] [s] [ ] [y] [o] [u] [r] [ ] [b] [a] [c] [k] [s] [t] [o] [r] [y] [?] [\"] [<U+000A>] name [:] [ ] [\"] history_17 \n",
      "personality ::= [<U+000A>] [S] [t] [r] [a] [n] [g] [e] [r] [:] [ ] [\"] [W] [h] [a] [t] ['] [s] [ ] [y] [o] [u] [r] [ ] [p] [e] [r] [s] [o] [n] [a] [l] [i] [t] [y] [?] [\"] [<U+000A>] name [:] [ ] [\"] personality_18 \n",
      "history_17 ::= [^<U+000A>] history_17 | [^<U+000A>] \n",
      "personality_18 ::= [^<U+000A>] personality_18 | [^<U+000A>] \n",
      "root ::= question-validation [<U+000A>] answer-validation [<U+000A>] critical-evaluation [<U+000A>] revised-qatuple \n",
      "question-validation ::= [#] [#] [#] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [ ] [C] [o] [n] [t] [e] [x] [t] [ ] [V] [a] [l] [i] [d] [a] [t] [i] [o] [n] [<U+000A>] special-term-check-question text-and-author-specificity scope-and-precision \n",
      "answer-validation ::= [#] [#] [#] [ ] [A] [n] [s] [w] [e] [r] [ ] [C] [o] [n] [t] [e] [x] [t] [ ] [V] [a] [l] [i] [d] [a] [t] [i] [o] [n] [:] [<U+000A>] special-term-check-answer specificity-and-clarity answer-only-context-issues \n",
      "critical-evaluation ::= [#] [#] [#] [ ] [C] [r] [i] [t] [i] [c] [a] [l] [ ] [E] [v] [a] [l] [u] [a] [t] [i] [o] [n] [ ] [a] [n] [d] [ ] [F] [i] [n] [a] [l] [ ] [J] [u] [d] [g] [m] [e] [n] [t] [:] [<U+000A>] evaluation final-judgment \n",
      "revised-qatuple ::= [#] [#] [#] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [ ] [R] [e] [w] [o] [r] [d] [i] [n] [g] [ ] [(] [u] [s] [i] [n] [g] [ ] [t] [e] [x] [t] [ ] [d] [e] [t] [a] [i] [l] [s] [ ] [a] [s] [ ] [r] [e] [f] [e] [r] [e] [n] [c] [e] [)] [:] [<U+000A>] revised-question-answer \n",
      "special-term-check-question ::= [#] [#] [#] [#] [ ] [S] [p] [e] [c] [i] [a] [l] [ ] [T] [e] [r] [m] [ ] [C] [o] [n] [t] [e] [x] [t] [ ] [C] [h] [e] [c] [k] [:] [ ] [S] [p] [e] [c] [i] [f] [i] [c] [a] [l] [l] [y] [ ] [c] [h] [e] [c] [k] [ ] [f] [o] [r] [ ] [u] [s] [e] [ ] [o] [f] [ ] [t] [h] [e] [ ] [t] [e] [r] [m] [s] [ ] [\"] [b] [o] [o] [k] [\"] [,] [ ] [\"] [t] [e] [x] [t] [\"] [,] [ ] [\"] [p] [a] [s] [s] [a] [g] [e] [\"] [,] [ ] [a] [n] [d] [ ] [\"] [e] [x] [c] [e] [r] [p] [t] [\"] [ ] [w] [i] [t] [h] [o] [u] [t] [ ] [c] [o] [n] [t] [e] [x] [t] [ ] [a] [b] [o] [u] [t] [ ] [w] [h] [i] [c] [h] [ ] [s] [p] [e] [c] [i] [f] [i] [c] [ ] [t] [h] [i] [n] [g] [ ] [i] [s] [ ] [b] [e] [i] [n] [g] [ ] [d] [i] [s] [c] [u] [s] [s] [e] [d] [.] [ ] question-term-detail [<U+000A>] \n",
      "text-and-author-specificity ::= [#] [#] [#] [#] [ ] [T] [e] [x] [t] [ ] [a] [n] [d] [ ] [A] [u] [t] [h] [o] [r] [ ] [S] [p] [e] [c] [i] [f] [i] [c] [i] [t] [y] [:] [ ] question-text-author-detail [<U+000A>] \n",
      "scope-and-precision ::= [#] [#] [#] [#] [ ] [S] [c] [o] [p] [e] [ ] [a] [n] [d] [ ] [P] [r] [e] [c] [i] [s] [i] [o] [n] [:] [ ] question-scope-detail [<U+000A>] \n",
      "question-term-detail ::= question-term-detail_22 \n",
      "question-text-author-detail ::= question-text-author-detail_23 \n",
      "question-scope-detail ::= question-scope-detail_24 \n",
      "special-term-check-answer ::= [#] [#] [#] [#] [ ] [S] [p] [e] [c] [i] [a] [l] [ ] [T] [e] [r] [m] [ ] [C] [o] [n] [t] [e] [x] [t] [ ] [C] [h] [e] [c] [k] [:] [ ] [S] [p] [e] [c] [i] [f] [i] [c] [a] [l] [l] [y] [ ] [c] [h] [e] [c] [k] [ ] [f] [o] [r] [ ] [u] [s] [e] [ ] [o] [f] [ ] [t] [h] [e] [ ] [t] [e] [r] [m] [s] [ ] [\"] [b] [o] [o] [k] [\"] [,] [ ] [\"] [t] [e] [x] [t] [\"] [,] [ ] [\"] [p] [a] [s] [s] [a] [g] [e] [\"] [,] [ ] [a] [n] [d] [ ] [\"] [e] [x] [c] [e] [r] [p] [t] [\"] [ ] [w] [i] [t] [h] [o] [u] [t] [ ] [c] [o] [n] [t] [e] [x] [t] [ ] [a] [b] [o] [u] [t] [ ] [w] [h] [i] [c] [h] [ ] [s] [p] [e] [c] [i] [f] [i] [c] [ ] [t] [h] [i] [n] [g] [ ] [i] [s] [ ] [b] [e] [i] [n] [g] [ ] [d] [i] [s] [c] [u] [s] [s] [e] [d] [.] [ ] answer-term-detail [<U+000A>] \n",
      "specificity-and-clarity ::= [#] [#] [#] [#] [ ] [S] [p] [e] [c] [i] [f] [i] [c] [i] [t] [y] [ ] [a] [n] [d] [ ] [C] [l] [a] [r] [i] [t] [y] [:] [ ] answer-specificity-detail [<U+000A>] \n",
      "answer-only-context-issues ::= [#] [#] [#] [#] [ ] [A] [n] [s] [w] [e] [r] [-] [O] [n] [l] [y] [ ] [C] [o] [n] [t] [e] [x] [t] [ ] [I] [s] [s] [u] [e] [s] [:] [ ] answer-context-issue-detail [<U+000A>] \n",
      "answer-term-detail ::= answer-term-detail_25 \n",
      "answer-specificity-detail ::= answer-specificity-detail_26 \n",
      "answer-context-issue-detail ::= answer-context-issue-detail_27 \n",
      "evaluation ::= [#] [#] [#] [#] [ ] [E] [v] [a] [l] [u] [a] [t] [i] [o] [n] [:] [ ] evaluation-detail [<U+000A>] \n",
      "final-judgment ::= [#] [#] [#] [#] [ ] [F] [i] [n] [a] [l] [ ] [j] [u] [d] [g] [m] [e] [n] [t] [:] [ ] judgment-detail [<U+000A>] \n",
      "evaluation-detail ::= evaluation-detail_28 \n",
      "judgment-detail ::= judgment-detail_29 \n",
      "revised-question-answer ::= [Q] [u] [e] [s] [t] [i] [o] [n] [:] [ ] revised-question-answer_30 [<U+000A>] [A] [n] [s] [w] [e] [r] [:] [ ] revised-question-answer_31 [<U+000A>] \n",
      "question-term-detail_22 ::= [^<U+000A>] question-term-detail_22 | [^<U+000A>] \n",
      "question-text-author-detail_23 ::= [^<U+000A>] question-text-author-detail_23 | [^<U+000A>] \n",
      "question-scope-detail_24 ::= [^<U+000A>] question-scope-detail_24 | [^<U+000A>] \n",
      "answer-term-detail_25 ::= [^<U+000A>] answer-term-detail_25 | [^<U+000A>] \n",
      "answer-specificity-detail_26 ::= [^<U+000A>] answer-specificity-detail_26 | [^<U+000A>] \n",
      "answer-context-issue-detail_27 ::= [^<U+000A>] answer-context-issue-detail_27 | [^<U+000A>] \n",
      "evaluation-detail_28 ::= [^<U+000A>] evaluation-detail_28 | [^<U+000A>] \n",
      "judgment-detail_29 ::= [P] [a] [s] [s] [.] | [F] [a] [i] [l] [.] | [R] [e] [w] [o] [r] [d] [.] \n",
      "revised-question-answer_30 ::= [^<U+000A>] revised-question-answer_30 | [^<U+000A>] \n",
      "revised-question-answer_31 ::= [^<U+000A>] revised-question-answer_31 | [^<U+000A>] \n",
      "root ::= [Q] [u] [e] [s] [t] [i] [o] [n] [:] [ ] root_1 [<U+000A>] [A] [n] [s] [w] [e] [r] [:] [ ] root_2 [<U+000A>] \n",
      "root_1 ::= [^<U+000A>] root_1 | [^<U+000A>] \n",
      "root_2 ::= [^<U+000A>] root_2 | [^<U+000A>] \n",
      "root ::= in-depth-analysis [<U+000A>] detailed-understanding [<U+000A>] targeted-comparison [<U+000A>] critical-evaluation \n",
      "in-depth-analysis ::= [#] [#] [#] [ ] [I] [n] [-] [D] [e] [p] [t] [h] [ ] [A] [n] [a] [l] [y] [s] [i] [s] [ ] [o] [f] [ ] [t] [h] [e] [ ] [T] [e] [x] [t] [:] [<U+000A>] content-and-depth type-of-information \n",
      "detailed-understanding ::= [#] [#] [#] [ ] [D] [e] [t] [a] [i] [l] [e] [d] [ ] [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] [i] [n] [g] [ ] [o] [f] [ ] [t] [h] [e] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [:] [<U+000A>] core-requirement depth-of-detail \n",
      "targeted-comparison ::= [#] [#] [#] [ ] [T] [a] [r] [g] [e] [t] [e] [d] [ ] [C] [o] [m] [p] [a] [r] [i] [s] [o] [n] [ ] [o] [f] [ ] [t] [h] [e] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [ ] [w] [i] [t] [h] [ ] [t] [h] [e] [ ] [T] [e] [x] [t] [:] [<U+000A>] content-match depth-match \n",
      "critical-evaluation ::= [#] [#] [#] [ ] [C] [r] [i] [t] [i] [c] [a] [l] [ ] [E] [v] [a] [l] [u] [a] [t] [i] [o] [n] [ ] [a] [n] [d] [ ] [F] [i] [n] [a] [l] [ ] [J] [u] [d] [g] [m] [e] [n] [t] [:] [<U+000A>] judgment \n",
      "content-and-depth ::= [#] [#] [#] [#] [ ] [C] [o] [n] [t] [e] [n] [t] [ ] [a] [n] [d] [ ] [D] [e] [p] [t] [h] [:] [ ] text-description [<U+000A>] \n",
      "type-of-information ::= [#] [#] [#] [#] [ ] [T] [y] [p] [e] [ ] [o] [f] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [:] [ ] information-description [<U+000A>] \n",
      "text-description ::= text-description_19 \n",
      "information-description ::= information-description_20 \n",
      "core-requirement ::= [#] [#] [#] [#] [ ] [C] [o] [r] [e] [ ] [R] [e] [q] [u] [i] [r] [e] [m] [e] [n] [t] [:] [ ] requirement-description [<U+000A>] \n",
      "depth-of-detail ::= [#] [#] [#] [#] [ ] [D] [e] [p] [t] [h] [ ] [o] [f] [ ] [D] [e] [t] [a] [i] [l] [:] [ ] detail-description [<U+000A>] \n",
      "requirement-description ::= requirement-description_21 \n",
      "detail-description ::= detail-description_22 \n",
      "content-match ::= [#] [#] [#] [#] [ ] [C] [o] [n] [t] [e] [n] [t] [ ] [M] [a] [t] [c] [h] [:] [ ] match-description [<U+000A>] \n",
      "depth-match ::= [#] [#] [#] [#] [ ] [D] [e] [p] [t] [h] [ ] [M] [a] [t] [c] [h] [:] [ ] depth-match-description [<U+000A>] \n",
      "match-description ::= match-description_23 \n",
      "depth-match-description ::= depth-match-description_24 \n",
      "judgment ::= judgment_18 \n",
      "judgment_18 ::= [^<U+000A>] judgment_18 | [^<U+000A>] \n",
      "text-description_19 ::= [^<U+000A>] text-description_19 | [^<U+000A>] \n",
      "information-description_20 ::= [^<U+000A>] information-description_20 | [^<U+000A>] \n",
      "requirement-description_21 ::= [^<U+000A>] requirement-description_21 | [^<U+000A>] \n",
      "detail-description_22 ::= [^<U+000A>] detail-description_22 | [^<U+000A>] \n",
      "match-description_23 ::= [^<U+000A>] match-description_23 | [^<U+000A>] \n",
      "depth-match-description_24 ::= [^<U+000A>] depth-match-description_24 | [^<U+000A>] \n",
      "relevance ::= [R] [e] [l] [e] [v] [a] [n] [t] [.] | [I] [r] [r] [e] [l] [e] [v] [a] [n] [t] [.] \n",
      "root ::= root_1 [<U+000A>] \n",
      "root_1 ::= [^<U+000A>] root_1 | [^<U+000A>] \n",
      "root ::= reasoning-start \n",
      "reasoning-start ::= reasoning-start_2 [.] \n",
      "reasoning-start_2 ::= [^<U+000A><U+0009>] reasoning-start_2 | [^<U+000A><U+0009>] \n",
      "root ::= consider-question-step consider-character-step constrain-step setting-step create-step second-message-step [<U+000A>] \n",
      "consider-question-step ::= [S] [t] [e] [p] [ ] consider-question-step_7 [0-9] [.] [ ] [F] [o] [c] [u] [s] [ ] [o] [n] [ ] [t] [h] [e] [ ] [q] [u] [e] [s] [t] [i] [o] [n] [ ] [a] [n] [d] [ ] [a] [n] [s] [w] [e] [r] [:] [ ] [T] [h] [e] [ ] [q] [u] [e] [s] [t] [i] [o] [n] consider-question-step_8 [<U+000A>] \n",
      "consider-character-step ::= [S] [t] [e] [p] [ ] consider-character-step_9 [0-9] [.] [ ] [C] [h] [a] [r] [a] [c] [t] [e] [r] [ ] [C] [o] [n] [s] [i] [d] [e] [r] [a] [t] [i] [o] [n] [:] [ ] [T] [h] [e] [ ] [p] [r] [i] [m] [a] [r] [y] [ ] [c] [h] [a] [r] [a] [c] [t] [e] [r] [ ] [i] [s] consider-character-step_10 [<U+000A>] \n",
      "constrain-step ::= [S] [t] [e] [p] [ ] constrain-step_11 [0-9] [.] [ ] [C] [o] [n] [s] [t] [r] [a] [i] [n] [ ] [t] [h] [e] [ ] [S] [c] [e] [n] [a] [r] [i] [o] [:] [ ] [T] [h] [e] [ ] [i] [n] [t] [e] [r] [a] [c] [t] [i] [o] [n] [ ] [i] [s] [ ] [l] [i] [m] [i] [t] [e] [d] [ ] [t] [o] [ ] [a] [ ] [s] [i] [n] [g] [l] [e] [ ] [q] [u] [e] [s] [t] [i] [o] [n] [ ] [f] [r] [o] [m] [ ] [t] [h] [e] [ ] [s] [e] [c] [o] [n] [d] [a] [r] [y] [ ] [c] [h] [a] [r] [a] [c] [t] [e] [r] [ ] [a] [n] [d] [ ] [a] [ ] [s] [i] [n] [g] [l] [e] [,] [ ] [f] [o] [c] [u] [s] [e] [d] [ ] [r] [e] [p] [l] [y] [ ] [f] [r] [o] [m] constrain-step_12 [<U+000A>] \n",
      "setting-step ::= [S] [t] [e] [p] [ ] setting-step_13 [0-9] [.] [ ] [S] [e] [t] [t] [i] [n] [g] [:] [ ] [G] [i] [v] [e] [n] [ ] [t] [h] [e] [ ] [s] [u] [b] [j] [e] [c] [t] [ ] [o] [f] [ ] [t] [h] [e] [ ] [q] [u] [e] [s] [t] [i] [o] [n] [,] [ ] [a] [n] [d] [ ] [t] [h] [e] [ ] [c] [h] [a] [r] [a] [c] [t] [e] [r] [ ] [c] [a] [r] [d] [,] [ ] [t] [h] [e] [ ] [s] [e] [t] [t] [i] [n] [g] [ ] [w] [i] [l] [l] [ ] [b] [e] setting-step_14 [<U+000A>] \n",
      "create-step ::= [S] [t] [e] [p] [ ] create-step_15 [0-9] [.] [ ] [I] [n] [t] [e] [r] [a] [c] [t] [i] [o] [n] [:] [ ] [G] [i] [v] [e] [n] [ ] [t] [h] [e] [s] [e] [ ] [c] [o] [n] [s] [t] [r] [a] [i] [n] [t] [s] [,] [ ] [t] [h] [e] [ ] [f] [i] [r] [s] [t] [ ] [m] [e] [s] [s] [a] [g] [e] [ ] [(] [d] [e] [l] [i] [v] [e] [r] [e] [d] [ ] [b] [y] [ ] [t] [h] [e] [ ] [s] [e] [c] [o] [n] [d] [a] [r] [y] [ ] [c] [h] [a] [r] [a] [c] [t] [e] [r] [)] [ ] [m] [i] [g] [h] [t] create-step_16 [<U+000A>] \n",
      "second-message-step ::= [S] [t] [e] [p] [ ] second-message-step_17 [0-9] [.] [ ] [I] [n] [ ] [t] [h] [e] [ ] [s] [e] [c] [o] [n] [d] [ ] [m] [e] [s] [s] [a] [g] [e] [,] second-message-step_18 [<U+000A>] \n",
      "consider-question-step_7 ::= [0-9] | \n",
      "consider-question-step_8 ::= [^<U+000A>] consider-question-step_8 | [^<U+000A>] \n",
      "consider-character-step_9 ::= [0-9] | \n",
      "consider-character-step_10 ::= [^<U+000A>] consider-character-step_10 | [^<U+000A>] \n",
      "constrain-step_11 ::= [0-9] | \n",
      "constrain-step_12 ::= [^<U+000A>] constrain-step_12 | [^<U+000A>] \n",
      "setting-step_13 ::= [0-9] | \n",
      "setting-step_14 ::= [^<U+000A>] setting-step_14 | [^<U+000A>] \n",
      "create-step_15 ::= [0-9] | \n",
      "create-step_16 ::= [^<U+000A>] create-step_16 | [^<U+000A>] \n",
      "second-message-step_17 ::= [0-9] | \n",
      "second-message-step_18 ::= [^<U+000A>] second-message-step_18 | [^<U+000A>] \n",
      "root ::= consider-question-step consider-character-step constrain-step setting-step create-step [<U+000A>] \n",
      "consider-question-step ::= [S] [t] [e] [p] [ ] consider-question-step_6 [0-9] [.] [ ] [F] [o] [c] [u] [s] [ ] [o] [n] [ ] [t] [h] [e] [ ] [q] [u] [e] [s] [t] [i] [o] [n] [ ] [a] [n] [d] [ ] [a] [n] [s] [w] [e] [r] [:] consider-question-step_7 [<U+000A>] \n",
      "consider-character-step ::= [S] [t] [e] [p] [ ] consider-character-step_8 [0-9] [.] [ ] [C] [h] [a] [r] [a] [c] [t] [e] [r] [ ] [C] [o] [n] [s] [i] [d] [e] [r] [a] [t] [i] [o] [n] [:] consider-character-step_9 [<U+000A>] \n",
      "constrain-step ::= [S] [t] [e] [p] [ ] constrain-step_10 [0-9] [.] [ ] [C] [o] [n] [s] [t] [r] [a] [i] [n] [ ] [t] [h] [e] [ ] [S] [c] [e] [n] [a] [r] [i] [o] [:] [ ] [T] [h] [e] [ ] [i] [n] [t] [e] [r] [a] [c] [t] [i] [o] [n] constrain-step_11 [<U+000A>] \n",
      "setting-step ::= [S] [t] [e] [p] [ ] setting-step_12 [0-9] [.] [ ] [S] [e] [t] [t] [i] [n] [g] [:] [ ] [G] [i] [v] [e] [n] [ ] [t] [h] [e] [ ] [s] [u] [b] [j] [e] [c] [t] [ ] [o] [f] [ ] [t] [h] [e] [ ] [q] [u] [e] [s] [t] [i] [o] [n] [,] [ ] [a] [n] [d] [ ] [t] [h] [e] [ ] [c] [h] [a] [r] [a] [c] [t] [e] [r] [ ] [c] [a] [r] [d] [,] [ ] [t] [h] [e] [ ] [s] [e] [t] [t] [i] [n] [g] [ ] [w] [i] [l] [l] [ ] [b] [e] setting-step_13 [<U+000A>] \n",
      "create-step ::= [S] [t] [e] [p] [ ] create-step_14 [0-9] [.] [ ] [I] [n] [t] [e] [r] [a] [c] [t] [i] [o] [n] [:] [ ] [G] [i] [v] [e] [n] [ ] [t] [h] [e] [s] [e] [ ] [c] [o] [n] [s] [t] [r] [a] [i] [n] [t] [s] [,] [ ] [t] [h] [e] [ ] [f] [i] [r] [s] [t] [ ] [m] [e] [s] [s] [a] [g] [e] [ ] [m] [i] [g] [h] [t] create-step_15 [<U+000A>] \n",
      "consider-question-step_6 ::= [0-9] | \n",
      "consider-question-step_7 ::= [^<U+000A>] consider-question-step_7 | [^<U+000A>] \n",
      "consider-character-step_8 ::= [0-9] | \n",
      "consider-character-step_9 ::= [^<U+000A>] consider-character-step_9 | [^<U+000A>] \n",
      "constrain-step_10 ::= [0-9] | \n",
      "constrain-step_11 ::= [^<U+000A>] constrain-step_11 | [^<U+000A>] \n",
      "setting-step_12 ::= [0-9] | \n",
      "setting-step_13 ::= [^<U+000A>] setting-step_13 | [^<U+000A>] \n",
      "create-step_14 ::= [0-9] | \n",
      "create-step_15 ::= [^<U+000A>] create-step_15 | [^<U+000A>] \n",
      "root ::= root_2 [<U+000A>] \n",
      "step ::= [S] [t] [e] [p] [ ] step_3 [0-9] [.] [ ] step_4 step_5 [<U+000A>] \n",
      "root_2 ::= step root_2 | step \n",
      "step_3 ::= [0-9] | \n",
      "step_4 ::= [R] [e] [a] [l] [i] [z] [e] | [R] [e] [c] [o] [g] [n] [i] [z] [e] | [C] [o] [n] [c] [l] [u] [d] [e] | [R] [e] [c] [a] [l] [l] | [R] [e] [m] [e] [m] [b] [e] [r] | [F] [o] [r] [m] [u] [l] [a] [t] [e] | [D] [e] [c] [o] [m] [p] [o] [s] [e] | [B] [r] [e] [a] [k] [ ] [d] [o] [w] [n] | [B] [r] [e] [a] [k] | [T] [h] [e] [r] [e] [f] [o] [r] [e] [,] [ ] [t] [h] [e] [ ] [a] [n] [s] [w] [e] [r] [ ] [i] [s] | [T] [h] [e] [ ] [a] [n] [s] [w] [e] [r] [ ] [i] [s] | [R] [e] [a] [l] [i] [s] [e] | [C] [a] [l] [c] [u] [l] [a] [t] [e] | [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] | [N] [o] [t] [e] | [T] [h] [e] [ ] [p] [l] [a] [n] [ ] [w] [i] [l] [l] \n",
      "step_5 ::= [^<U+000A>] step_5 | [^<U+000A>] \n",
      "root ::= understand-question-step compare-question-step understand-answer-step compare-step final-step [<U+000A>] \n",
      "understand-question-step ::= [S] [t] [e] [p] [ ] understand-question-step_6 [0-9] [.] [ ] [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] [ ] [t] [h] [e] [ ] [p] [r] [o] [v] [i] [d] [e] [d] [ ] [q] [u] [e] [s] [t] [i] [o] [n] [:] understand-question-step_7 [<U+000A>] \n",
      "compare-question-step ::= [S] [t] [e] [p] [ ] compare-question-step_8 [0-9] [.] [ ] [C] [o] [m] [p] [a] [r] [e] [ ] [t] [h] [e] [ ] [c] [o] [n] [v] [e] [r] [s] [a] [t] [i] [o] [n] ['] [s] [ ] [q] [u] [e] [s] [t] [i] [o] [n] [:] [ ] compare-question-step_9 [<U+000A>] \n",
      "understand-answer-step ::= [S] [t] [e] [p] [ ] understand-answer-step_10 [0-9] [.] [ ] [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] [ ] [t] [h] [e] [ ] [p] [r] [o] [v] [i] [d] [e] [d] [ ] [a] [n] [s] [w] [e] [r] [:] understand-answer-step_11 [<U+000A>] \n",
      "compare-step ::= [S] [t] [e] [p] [ ] compare-step_12 [0-9] [.] [ ] [C] [o] [m] [p] [a] [r] [e] [ ] [t] [h] [e] [ ] [c] [o] [n] [v] [e] [r] [s] [a] [t] [i] [o] [n] ['] [s] [ ] [a] [n] [s] [w] [e] [r] [:] compare-step_13 [<U+000A>] \n",
      "final-step ::= [S] [t] [e] [p] [ ] final-step_14 [0-9] [.] [ ] [F] [i] [n] [a] [l] [ ] [J] [u] [d] [g] [e] [m] [e] [n] [t] [:] [ ] final-step_15 [<U+000A>] \n",
      "understand-question-step_6 ::= [0-9] | \n",
      "understand-question-step_7 ::= [^<U+000A>] understand-question-step_7 | [^<U+000A>] \n",
      "compare-question-step_8 ::= [0-9] | \n",
      "compare-question-step_9 ::= [^<U+000A>] compare-question-step_9 | [^<U+000A>] \n",
      "understand-answer-step_10 ::= [0-9] | \n",
      "understand-answer-step_11 ::= [^<U+000A>] understand-answer-step_11 | [^<U+000A>] \n",
      "compare-step_12 ::= [0-9] | \n",
      "compare-step_13 ::= [^<U+000A>] compare-step_13 | [^<U+000A>] \n",
      "final-step_14 ::= [0-9] | \n",
      "final-step_15 ::= [I] [n] [c] [o] [n] [s] [i] [s] [t] [e] [n] [t] | [C] [o] [n] [s] [i] [s] [t] [e] [n] [t] \n",
      "root ::= sequential-matching-section accuracy-check-section conclusion-section \n",
      "sequential-matching-section ::= [#] [#] [ ] [S] [e] [q] [u] [e] [n] [t] [i] [a] [l] [ ] [M] [a] [t] [c] [h] [i] [n] [g] [ ] [o] [f] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [s] [ ] [i] [n] [ ] [t] [h] [e] [ ] [C] [o] [n] [v] [e] [r] [s] [a] [t] [i] [o] [n] [:] [<U+000A>] [#] [#] [#] [ ] [S] [e] [q] [u] [e] [n] [c] [e] [ ] [a] [n] [d] [ ] [P] [h] [r] [a] [s] [i] [n] [g] [ ] [o] [f] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [s] [:] [<U+000A>] sequential-matching-section_5 \n",
      "accuracy-check-section ::= [#] [#] [ ] [A] [c] [c] [u] [r] [a] [c] [y] [ ] [C] [h] [e] [c] [k] [ ] [f] [o] [r] [ ] [A] [n] [s] [w] [e] [r] [s] [ ] [i] [n] [ ] [t] [h] [e] [ ] [C] [o] [n] [v] [e] [r] [s] [a] [t] [i] [o] [n] [:] [<U+000A>] [#] [#] [#] [ ] [M] [a] [t] [c] [h] [i] [n] [g] [ ] [A] [n] [s] [w] [e] [r] [s] [ ] [w] [i] [t] [h] [ ] [P] [r] [o] [v] [i] [d] [e] [d] [ ] [C] [o] [n] [t] [e] [n] [t] [:] [<U+000A>] accuracy-check-section_7 \n",
      "conclusion-section ::= [#] [#] [ ] [C] [o] [n] [c] [l] [u] [s] [i] [o] [n] [:] [<U+000A>] conclusion-section_9 \n",
      "matching-statement ::= number [.] [ ] matching-statement_11 [<U+000A>] \n",
      "sequential-matching-section_5 ::= matching-statement sequential-matching-section_5 | matching-statement \n",
      "accuracy-statement ::= number [.] [ ] accuracy-statement_12 [<U+000A>] \n",
      "accuracy-check-section_7 ::= accuracy-statement accuracy-check-section_7 | accuracy-statement \n",
      "conclusion-statement ::= [ ] [ ] [-] [ ] conclusion-statement_13 [<U+000A>] \n",
      "conclusion-section_9 ::= conclusion-statement conclusion-section_9 | conclusion-statement \n",
      "number ::= [1-9] \n",
      "matching-statement_11 ::= [^<U+000A>] matching-statement_11 | [^<U+000A>] \n",
      "accuracy-statement_12 ::= [^<U+000A>] accuracy-statement_12 | [^<U+000A>] \n",
      "conclusion-statement_13 ::= [^<U+000A>] conclusion-statement_13 | [^<U+000A>] \n",
      "final-judgement ::= [ ] [ ] [-] [ ] [F] [i] [n] [a] [l] [ ] [J] [u] [d] [g] [m] [e] [n] [t] [:] final-judgement_15 \n",
      "final-judgement_15 ::= [^<U+000A>] final-judgement_15 | [^<U+000A>] \n",
      "root ::= root_1 \n",
      "root_1 ::= question-one answer [<U+000A>] \n",
      "question-one ::= [1] [.] [)] [ ] question-one_8 [?.!] [<U+000A>] \n",
      "answer ::= [A] [n] [s] [w] [e] [r] [:] [ ] answer_4 [<U+000A>] \n",
      "answer_4 ::= [^<U+000A>] answer_4 | [^<U+000A>] \n",
      "number ::= [1-9] number_6 number_7 \n",
      "number_6 ::= [0-9] | \n",
      "number_7 ::= [0-9] | \n",
      "question-one_8 ::= [^<U+000A>] question-one_8 | [^<U+000A>] \n",
      "root ::= root_1 root_4 root_6 root_8 \n",
      "root_1 ::= question-one answer [<U+000A>] \n",
      "question-one ::= [1] [.] [)] [ ] question-one_14 [?.!] [<U+000A>] [<U+000A>] \n",
      "answer ::= [A] [n] [s] [w] [e] [r] [:] [ ] answer_10 [<U+000A>] \n",
      "root_4 ::= question-two answer [<U+000A>] \n",
      "question-two ::= [2] [.] [)] [ ] question-two_15 [?.!] [<U+000A>] [<U+000A>] \n",
      "root_6 ::= question-three answer [<U+000A>] \n",
      "question-three ::= [3] [.] [)] [ ] question-three_16 [?.!] [<U+000A>] [<U+000A>] \n",
      "root_8 ::= question-four answer \n",
      "question-four ::= [4] [.] [)] [ ] question-four_17 [?.!] [<U+000A>] [<U+000A>] \n",
      "answer_10 ::= [^<U+000A>] answer_10 | [^<U+000A>] \n",
      "number ::= [1-9] number_12 number_13 \n",
      "number_12 ::= [0-9] | \n",
      "number_13 ::= [0-9] | \n",
      "question-one_14 ::= [^<U+000A>] question-one_14 | [^<U+000A>] \n",
      "question-two_15 ::= [^<U+000A>] question-two_15 | [^<U+000A>] \n",
      "question-three_16 ::= [^<U+000A>] question-three_16 | [^<U+000A>] \n",
      "question-four_17 ::= [^<U+000A>] question-four_17 | [^<U+000A>] \n",
      "root ::= identify-step generate-step brainstorm-step relationships-step if-then-step make-suitable-step \n",
      "identify-step ::= [S] [t] [e] [p] [ ] identify-step_7 [0-9] [.] [ ] [I] [d] [e] [n] [t] [i] [f] [y] [ ] [K] [e] [y] [ ] [T] [o] [p] [i] [c] [s] [:] identify-step_8 [<U+000A>] \n",
      "root ::= normalization-block core-components-block comparative-analysis-block criteria-block conclusion-block \n",
      "normalization-block ::= [#] [#] [ ] [N] [o] [r] [m] [a] [l] [i] [z] [a] [t] [i] [o] [n] [ ] [o] [f] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [s] [:] [<U+000A>] normalization-block_7 \n",
      "core-components-block ::= [#] [#] [ ] [I] [d] [e] [n] [t] [i] [f] [i] [c] [a] [t] [i] [o] [n] [ ] [o] [f] [ ] [C] [o] [r] [e] [ ] [C] [o] [m] [p] [o] [n] [e] [n] [t] [s] [:] [<U+000A>] [#] [#] [#] [ ] [S] [u] [b] [j] [e] [c] [t] [ ] [M] [a] [t] [t] [e] [r] [:] [<U+000A>] core-components-block_10 [#] [#] [#] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [ ] [S] [o] [u] [g] [h] [t] [:] [<U+000A>] core-components-block_12 \n",
      "comparative-analysis-block ::= [#] [#] [ ] [C] [o] [m] [p] [a] [r] [a] [t] [i] [v] [e] [ ] [A] [n] [a] [l] [y] [s] [i] [s] [ ] [A] [c] [r] [o] [s] [s] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [s] [:] [<U+000A>] [#] [#] [#] [ ] [D] [i] [r] [e] [c] [t] [ ] [C] [o] [m] [p] [a] [r] [i] [s] [o] [n] [:] [<U+000A>] comparative-analysis-block_17 [#] [#] [#] [ ] [O] [v] [e] [r] [l] [a] [p] [ ] [i] [n] [ ] [C] [o] [r] [e] [ ] [C] [o] [m] [p] [o] [n] [e] [n] [t] [s] [:] [<U+000A>] comparative-analysis-block_18 [<U+000A>] \n",
      "criteria-block ::= [#] [#] [ ] [C] [r] [i] [t] [e] [r] [i] [a] [ ] [f] [o] [r] [ ] [D] [u] [p] [l] [i] [c] [a] [t] [i] [o] [n] [:] [<U+000A>] [#] [#] [#] [ ] [E] [x] [a] [c] [t] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [ ] [M] [a] [t] [c] [h] [:] [<U+000A>] content [#] [#] [#] [ ] [N] [e] [g] [a] [t] [i] [o] [n] [ ] [o] [f] [ ] [M] [i] [n] [o] [r] [ ] [D] [i] [f] [f] [e] [r] [e] [n] [c] [e] [s] [:] [<U+000A>] content [<U+000A>] \n",
      "conclusion-block ::= [#] [#] [ ] [C] [o] [n] [c] [l] [u] [s] [i] [o] [n] [ ] [a] [n] [d] [ ] [L] [a] [b] [e] [l] [i] [n] [g] [:] [<U+000A>] content [<U+000A>] [<U+000A>] [#] [#] [ ] [U] [n] [i] [q] [u] [e] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [s] [:] [ ] unique-questions [<U+000A>] \n",
      "normalized-question ::= [-] [ ] [\"] content [\"] [<U+000A>] [ ] [ ] [-] [ ] [N] [o] [r] [m] [a] [l] [i] [z] [e] [d] [:] [ ] content [<U+000A>] \n",
      "normalization-block_7 ::= normalized-question normalization-block_7 | normalized-question \n",
      "content ::= content_25 \n",
      "subject-matter ::= [-] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [ ] subject-matter_14 [:] [ ] content [<U+000A>] \n",
      "core-components-block_10 ::= subject-matter core-components-block_10 | subject-matter \n",
      "information-sought ::= [-] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [ ] information-sought_15 [:] [ ] content [<U+000A>] \n",
      "core-components-block_12 ::= information-sought core-components-block_12 | information-sought \n",
      "digit ::= [0-9] \n",
      "subject-matter_14 ::= digit subject-matter_14 | digit \n",
      "information-sought_15 ::= digit information-sought_15 | digit \n",
      "bullet-item ::= [-] [ ] content [<U+000A>] \n",
      "comparative-analysis-block_17 ::= bullet-item comparative-analysis-block_17 | bullet-item \n",
      "comparative-analysis-block_18 ::= bullet-item comparative-analysis-block_18 | bullet-item \n",
      "unique-questions ::= [[] unique-questions_20 unique-questions_23 []] \n",
      "unique-questions_20 ::= digit unique-questions_20 | digit \n",
      "unique-questions_21 ::= [,] [ ] unique-questions_22 \n",
      "unique-questions_22 ::= digit unique-questions_22 | digit \n",
      "unique-questions_23 ::= unique-questions_21 unique-questions_23 | \n",
      "char ::= [^<U+000A>] \n",
      "content_25 ::= char content_25 | char \n",
      "root ::= analyze-step root_3 [<U+000A>] [<U+000A>] [B] [e] [g] [i] [n] [ ] [E] [d] [i] [t] [:] [ ] root_4 \n",
      "analyze-step ::= [S] [t] [e] [p] [ ] analyze-step_8 [0-9] [.] [ ] [A] [n] [a] [l] [y] [z] [e] analyze-step_9 [<U+000A>] \n",
      "step ::= [S] [t] [e] [p] [ ] step_5 [0-9] [.] [ ] step_6 step_7 [<U+000A>] \n",
      "root_3 ::= step root_3 | step \n",
      "root_4 ::= [^<U+000A>] root_4 | [^<U+000A>] \n",
      "step_5 ::= [0-9] | \n",
      "step_6 ::= [A] [n] [a] [l] [y] [z] [e] | [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] | [C] [o] [m] [p] [a] [r] [e] | [S] [k] [i] [p] | [N] [o] [t] [i] [c] [e] | [N] [o] [t] [e] | [T] [h] [e] [r] [e] [ ] [i] [s] | [E] [r] [r] [o] [r] | [I] [ ] [f] [o] [u] [n] [d] | [E] [n] [d] | [T] [h] [e] [r] [e] [ ] [a] [r] [e] \n",
      "step_7 ::= [^<U+000A>] step_7 | [^<U+000A>] \n",
      "analyze-step_8 ::= [0-9] | \n",
      "analyze-step_9 ::= [^<U+000A>] analyze-step_9 | [^<U+000A>] \n",
      "root ::= identify-content-step evaluate-relevance-step assess-contexts-and-formats-step assess-possibility-step determine-suitability-step check-contextual-completeness-step final-step [<U+000A>] \n",
      "identify-content-step ::= [S] [t] [e] [p] [ ] identify-content-step_8 [0-9] [.] [ ] [I] [d] [e] [n] [t] [i] [f] [y] [ ] [P] [a] [r] [a] [g] [r] [a] [p] [h] [ ] [C] [o] [n] [t] [e] [n] [t] [:] [ ] identify-content-step_9 [<U+000A>] \n",
      "evaluate-relevance-step ::= [S] [t] [e] [p] [ ] evaluate-relevance-step_10 [0-9] [.] [ ] [E] [v] [a] [l] [u] [a] [t] [e] [ ] [E] [d] [u] [c] [a] [t] [i] [o] [n] [a] [l] [ ] [R] [e] [l] [e] [v] [a] [n] [c] [e] [:] [ ] evaluate-relevance-step_11 [<U+000A>] \n",
      "assess-contexts-and-formats-step ::= [S] [t] [e] [p] [ ] assess-contexts-and-formats-step_12 [0-9] [.] [ ] [A] [s] [s] [e] [s] [s] [ ] [S] [p] [e] [c] [i] [f] [i] [c] [ ] [C] [o] [n] [t] [e] [x] [t] [s] [ ] [a] [n] [d] [ ] [F] [o] [r] [m] [a] [t] [s] [:] [<U+000A>] context-format-bullets \n",
      "assess-possibility-step ::= [S] [t] [e] [p] [ ] assess-possibility-step_14 [0-9] [.] [ ] [A] [s] [s] [e] [s] [s] [ ] [t] [h] [e] [ ] [P] [o] [s] [s] [i] [b] [i] [l] [i] [t] [y] [ ] [o] [f] [ ] [F] [o] [r] [m] [u] [l] [a] [t] [i] [n] [g] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [s] [:] [ ] assess-possibility-step_15 [<U+000A>] \n",
      "determine-suitability-step ::= [S] [t] [e] [p] [ ] determine-suitability-step_16 [0-9] [.] [ ] [D] [e] [t] [e] [r] [m] [i] [n] [e] [ ] [S] [u] [i] [t] [a] [b] [i] [l] [i] [t] [y] [ ] [f] [o] [r] [ ] [E] [d] [u] [c] [a] [t] [i] [o] [n] [a] [l] [ ] [P] [u] [r] [p] [o] [s] [e] [s] [:] [ ] determine-suitability-step_17 [<U+000A>] \n",
      "check-contextual-completeness-step ::= [S] [t] [e] [p] [ ] check-contextual-completeness-step_18 [0-9] [.] [ ] [C] [h] [e] [c] [k] [ ] [f] [o] [r] [ ] [C] [o] [n] [t] [e] [x] [t] [u] [a] [l] [ ] [C] [o] [m] [p] [l] [e] [t] [e] [n] [e] [s] [s] [:] [ ] check-contextual-completeness-step_19 [<U+000A>] \n",
      "final-step ::= [S] [t] [e] [p] [ ] final-step_20 [0-9] [.] [ ] [F] [i] [n] [a] [l] [ ] [J] [u] [d] [g] [m] [e] [n] [t] [:] [ ] final-step_21 [<U+000A>] \n",
      "identify-content-step_8 ::= [0-9] | \n",
      "identify-content-step_9 ::= [^<U+000A>] identify-content-step_9 | [^<U+000A>] \n",
      "evaluate-relevance-step_10 ::= [0-9] | \n",
      "evaluate-relevance-step_11 ::= [^<U+000A>] evaluate-relevance-step_11 | [^<U+000A>] \n",
      "assess-contexts-and-formats-step_12 ::= [0-9] | \n",
      "context-format-bullets ::= context-format-bullets_23 \n",
      "assess-possibility-step_14 ::= [0-9] | \n",
      "assess-possibility-step_15 ::= [^<U+000A>] assess-possibility-step_15 | [^<U+000A>] \n",
      "determine-suitability-step_16 ::= [0-9] | \n",
      "determine-suitability-step_17 ::= [^<U+000A>] determine-suitability-step_17 | [^<U+000A>] \n",
      "check-contextual-completeness-step_18 ::= [0-9] | \n",
      "check-contextual-completeness-step_19 ::= [^<U+000A>] check-contextual-completeness-step_19 | [^<U+000A>] \n",
      "final-step_20 ::= [0-9] | \n",
      "final-step_21 ::= [U] [n] [s] [u] [i] [t] [a] [b] [l] [e] | [S] [u] [i] [t] [a] [b] [l] [e] | [s] [u] [i] [t] [a] [b] [l] [e] | [u] [n] [s] [u] [i] [t] [a] [b] [l] [e] \n",
      "bullet-item ::= [ ] [ ] [-] [ ] bullet-item-detail [<U+000A>] \n",
      "context-format-bullets_23 ::= bullet-item context-format-bullets_23 | bullet-item \n",
      "bullet-item-detail ::= bullet-item-detail_25 \n",
      "bullet-item-detail_25 ::= [^<U+000A>] bullet-item-detail_25 | [^<U+000A>] \n",
      "root ::= analyze-step understand-step identify-step plan-step \n",
      "analyze-step ::= [S] [t] [e] [p] [ ] analyze-step_5 [0-9] [.] [ ] [A] [n] [a] [l] [y] [z] [e] [ ] [t] [h] [e] [ ] [T] [e] [x] [t] [:] analyze-step_6 [<U+000A>] \n",
      "understand-step ::= [S] [t] [e] [p] [ ] understand-step_7 [0-9] [.] [ ] [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] [ ] [t] [h] [e] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [:] understand-step_8 [<U+000A>] \n",
      "identify-step ::= [S] [t] [e] [p] [ ] identify-step_9 [0-9] [.] [ ] [I] [d] [e] [n] [t] [i] [f] [y] [ ] [t] [h] [e] [ ] [I] [n] [c] [o] [r] [r] [e] [c] [t] [ ] [P] [a] [r] [t] [ ] [o] [f] [ ] [t] [h] [e] [ ] [A] [n] [s] [w] [e] [r] [:] identify-step_10 [<U+000A>] \n",
      "plan-step ::= [S] [t] [e] [p] [ ] plan-step_11 [0-9] [.] [ ] [P] [l] [a] [n] [ ] [a] [ ] [C] [o] [r] [r] [e] [c] [t] [e] [d] [ ] [A] [n] [s] [w] [e] [r] [:] plan-step_12 [<U+000A>] \n",
      "analyze-step_5 ::= [0-9] | \n",
      "analyze-step_6 ::= [^<U+000A>] analyze-step_6 | [^<U+000A>] \n",
      "understand-step_7 ::= [0-9] | \n",
      "understand-step_8 ::= [^<U+000A>] understand-step_8 | [^<U+000A>] \n",
      "identify-step_9 ::= [0-9] | \n",
      "identify-step_10 ::= [^<U+000A>] identify-step_10 | [^<U+000A>] \n",
      "plan-step_11 ::= [0-9] | \n",
      "plan-step_12 ::= [^<U+000A>] plan-step_12 | [^<U+000A>] \n",
      "root ::= analyze-step identify-step generate-step refine-step ensure-step end-of-reasoning \n",
      "analyze-step ::= [S] [t] [e] [p] [ ] analyze-step_11 [0-9] [.] [ ] [A] [n] [a] [l] [y] [z] [e] [ ] [t] [h] [e] [ ] [R] [e] [a] [s] [o] [n] [ ] [f] [o] [r] [ ] [t] [h] [e] [ ] [F] [l] [a] [w] [:] analyze-step_12 [<U+000A>] \n",
      "identify-step ::= [S] [t] [e] [p] [ ] identify-step_13 [0-9] [.] [ ] [I] [d] [e] [n] [t] [i] [f] [y] [ ] [K] [e] [y] [ ] [C] [o] [n] [c] [e] [p] [t] [s] [ ] [i] [n] [ ] [P] [a] [r] [a] [g] [r] [a] [p] [h] [s] [:] identify-step_14 [<U+000A>] \n",
      "generate-step ::= [S] [t] [e] [p] [ ] generate-step_15 [0-9] [.] [ ] [G] [e] [n] [e] [r] [a] [t] [e] [ ] [a] [ ] [N] [e] [w] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [ ] [I] [d] [e] [a] [:] generate-step_16 [<U+000A>] \n",
      "refine-step ::= [S] [t] [e] [p] [ ] refine-step_17 [0-9] [.] [ ] [R] [e] [f] [i] [n] [e] [ ] [t] [h] [e] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [:] refine-step_18 [<U+000A>] \n",
      "ensure-step ::= [S] [t] [e] [p] [ ] ensure-step_19 [0-9] [.] [ ] [E] [n] [s] [u] [r] [e] [ ] [A] [l] [i] [g] [n] [m] [e] [n] [t] [ ] [w] [i] [t] [h] [ ] [T] [e] [x] [t] [:] ensure-step_20 [<U+000A>] \n",
      "end-of-reasoning ::= [S] [t] [e] [p] [ ] end-of-reasoning_21 [0-9] [.] [ ] [E] [n] [d] end-of-reasoning_22 [<U+000A>] \n",
      "step ::= [S] [t] [e] [p] [ ] step_8 [0-9] [.] [ ] step_9 step_10 [<U+000A>] \n",
      "step_8 ::= [0-9] | \n",
      "step_9 ::= [A] [n] [a] [l] [y] [z] [e] | [I] [d] [e] [n] [t] [i] [f] [y] | [G] [e] [n] [e] [r] [a] [t] [e] | [R] [e] [f] [i] [n] [e] | [E] [n] [s] [u] [r] [e] \n",
      "step_10 ::= [^<U+000A>] step_10 | [^<U+000A>] \n",
      "analyze-step_11 ::= [0-9] | \n",
      "analyze-step_12 ::= [^<U+000A>] analyze-step_12 | [^<U+000A>] \n",
      "identify-step_13 ::= [0-9] | \n",
      "identify-step_14 ::= [^<U+000A>] identify-step_14 | [^<U+000A>] \n",
      "generate-step_15 ::= [0-9] | \n",
      "generate-step_16 ::= [^<U+000A>] generate-step_16 | [^<U+000A>] \n",
      "refine-step_17 ::= [0-9] | \n",
      "refine-step_18 ::= [^<U+000A>] refine-step_18 | [^<U+000A>] \n",
      "ensure-step_19 ::= [0-9] | \n",
      "ensure-step_20 ::= [^<U+000A>] ensure-step_20 | [^<U+000A>] \n",
      "end-of-reasoning_21 ::= [0-9] | \n",
      "end-of-reasoning_22 ::= [^<U+000A>] end-of-reasoning_22 | [^<U+000A>] \n",
      "root ::= root_1 \n",
      "root_1 ::= [^<U+0009>] root_1 | [^<U+0009>] \n",
      "statement ::= statement_3 [:] statement_4 [<U+000A>] \n",
      "statement_3 ::= [^<U+000A>] statement_3 | [^<U+000A>] \n",
      "statement_4 ::= [^<U+000A>] statement_4 | [^<U+000A>] \n",
      "anything ::= anything_6 \n",
      "anything_6 ::= [^<U+0009>] anything_6 | [^<U+0009>] \n",
      "root ::= root_1 [:] root_2 \n",
      "root_1 ::= [^<U+000A>] root_1 | [^<U+000A>] \n",
      "root_2 ::= [^<U+000A>] root_2 | [^<U+000A>] \n",
      "root ::= step step root_2 [<U+000A>] \n",
      "step ::= [S] [t] [e] [p] [ ] step_5 [0-9] [.] [ ] step_6 step_7 [<U+000A>] \n",
      "root_2 ::= step root_2 | step \n",
      "reasoning-start ::= reasoning-start_4 [.] \n",
      "reasoning-start_4 ::= [^<U+000A><U+0009>] reasoning-start_4 | [^<U+000A><U+0009>] \n",
      "step_5 ::= [0-9] | \n",
      "step_6 ::= [A] [n] [a] [l] [y] [z] [e] | [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] | [C] [o] [m] [p] [a] [r] [e] | [S] [k] [i] [p] | [F] [i] [n] [a] [l] \n",
      "step_7 ::= [^<U+000A>] step_7 | [^<U+000A>] \n",
      "relevant ::= [ ] [r] [e] [l] [e] [v] [a] [n] [t] | [ ] [R] [e] [l] [e] [v] [a] [n] [t] \n",
      "irrelevant ::= [ ] [i] [r] [r] [e] [l] [e] [v] [a] [n] [t] | [ ] [I] [r] [r] [e] [l] [e] [v] [a] [n] [t] \n",
      "root ::= reasoning \n",
      "reasoning ::= reasoning_2 [.] \n",
      "reasoning_2 ::= [^<U+000A>] reasoning_2 | [^<U+000A>] \n",
      "root ::= reasoning \n",
      "reasoning ::= reasoning_2 [\"] [\"] [\"] \n",
      "reasoning_2 ::= [^<U+000A>] reasoning_2 | [^<U+000A>] \n",
      "root ::= statement [<U+000A>] [<U+000A>] response [<U+000A>] \n",
      "statement ::= statement_3 [:] statement_4 \n",
      "response ::= response_5 [:] response_6 \n",
      "statement_3 ::= [^<U+000A>] statement_3 | [^<U+000A>] \n",
      "statement_4 ::= [^<U+000A>] statement_4 | [^<U+000A>] \n",
      "response_5 ::= [^<U+000A>] response_5 | [^<U+000A>] \n",
      "response_6 ::= [^<U+000A>] response_6 | [^<U+000A>] \n",
      "character-name ::= word | word word | word word word | word word word word | word word word word word | word word word word word word \n",
      "word ::= word_11 \n",
      "character-name_9 ::= [-] word \n",
      "character-name_10 ::= character-name_9 character-name_10 | \n",
      "word_11 ::= [A-Za-z] word_11 | [A-Za-z] \n",
      "dialogue-line ::= dialogue-line_13 \n",
      "dialogue-line_13 ::= [^<U+000A>] dialogue-line_13 | [^<U+000A>] \n",
      "root ::= text-analysis answer-breakdown accuracy-check final-judgment \n",
      "text-analysis ::= [#] [#] [#] [ ] [T] [e] [x] [t] [ ] [A] [n] [a] [l] [y] [s] [i] [s] [:] [<U+000A>] identify-key-info categorize-info-type \n",
      "answer-breakdown ::= [#] [#] [#] [ ] [A] [n] [s] [w] [e] [r] [ ] [B] [r] [e] [a] [k] [d] [o] [w] [n] [:] [<U+000A>] dissect-answer identify-answer-type \n",
      "accuracy-check ::= [#] [#] [#] [ ] [A] [c] [c] [u] [r] [a] [c] [y] [ ] [C] [h] [e] [c] [k] [:] [<U+000A>] direct-comparison inference-and-contextual-alignment \n",
      "final-judgment ::= [#] [#] [#] [ ] [F] [i] [n] [a] [l] [ ] [J] [u] [d] [g] [m] [e] [n] [t] [:] [<U+000A>] comprehensive-assessment overall-accuracy-determination \n",
      "identify-key-info ::= [#] [#] [#] [#] [ ] [I] [d] [e] [n] [t] [i] [f] [y] [ ] [K] [e] [y] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [:] [ ] text-info-detail [<U+000A>] \n",
      "categorize-info-type ::= [#] [#] [#] [#] [ ] [C] [a] [t] [e] [g] [o] [r] [i] [z] [e] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [ ] [T] [y] [p] [e] [:] [ ] info-type-detail [<U+000A>] [<U+000A>] \n",
      "text-info-detail ::= text-info-detail_24 \n",
      "info-type-detail ::= info-type-detail_25 \n",
      "dissect-answer ::= [#] [#] [#] [#] [ ] [D] [i] [s] [s] [e] [c] [t] [ ] [t] [h] [e] [ ] [A] [n] [s] [w] [e] [r] [:] [ ] answer-detail [<U+000A>] \n",
      "identify-answer-type ::= [#] [#] [#] [#] [ ] [I] [d] [e] [n] [t] [i] [f] [y] [ ] [A] [n] [s] [w] [e] [r] [ ] [T] [y] [p] [e] [:] [ ] answer-type-detail [<U+000A>] [<U+000A>] \n",
      "answer-detail ::= answer-detail_26 \n",
      "answer-type-detail ::= answer-type-detail_27 \n",
      "direct-comparison ::= [#] [#] [#] [#] [ ] [D] [i] [r] [e] [c] [t] [ ] [C] [o] [m] [p] [a] [r] [i] [s] [o] [n] [ ] [f] [o] [r] [ ] [F] [a] [c] [t] [u] [a] [l] [ ] [A] [c] [c] [u] [r] [a] [c] [y] [:] [<U+000A>] comparison-points \n",
      "inference-and-contextual-alignment ::= [#] [#] [#] [#] [ ] [I] [n] [f] [e] [r] [e] [n] [c] [e] [ ] [a] [n] [d] [ ] [C] [o] [n] [t] [e] [x] [t] [u] [a] [l] [ ] [A] [l] [i] [g] [n] [m] [e] [n] [t] [:] [ ] contextual-alignment-detail [<U+000A>] [<U+000A>] \n",
      "comparison-points ::= comparison-points_17 \n",
      "bullet-point ::= [ ] [ ] [-] [ ] comparison-point-detail [<U+000A>] \n",
      "comparison-points_17 ::= bullet-point comparison-points_17 | bullet-point \n",
      "comparison-point-detail ::= comparison-point-detail_28 \n",
      "contextual-alignment-detail ::= contextual-alignment-detail_29 \n",
      "comprehensive-assessment ::= [#] [#] [#] [#] [ ] [C] [o] [m] [p] [r] [e] [h] [e] [n] [s] [i] [v] [e] [ ] [A] [s] [s] [e] [s] [s] [m] [e] [n] [t] [:] [ ] assessment-detail [<U+000A>] \n",
      "overall-accuracy-determination ::= [#] [#] [#] [#] [ ] [O] [v] [e] [r] [a] [l] [l] [ ] [A] [c] [c] [u] [r] [a] [c] [y] [ ] [D] [e] [t] [e] [r] [m] [i] [n] [a] [t] [i] [o] [n] [:] [ ] accuracy-detail [<U+000A>] \n",
      "assessment-detail ::= assessment-detail_30 \n",
      "accuracy-detail ::= accuracy-detail_31 \n",
      "text-info-detail_24 ::= [^<U+000A>] text-info-detail_24 | [^<U+000A>] \n",
      "info-type-detail_25 ::= [^<U+000A>] info-type-detail_25 | [^<U+000A>] \n",
      "answer-detail_26 ::= [^<U+000A>] answer-detail_26 | [^<U+000A>] \n",
      "answer-type-detail_27 ::= [^<U+000A>] answer-type-detail_27 | [^<U+000A>] \n",
      "comparison-point-detail_28 ::= [^<U+000A>] comparison-point-detail_28 | [^<U+000A>] \n",
      "contextual-alignment-detail_29 ::= [^<U+000A>] contextual-alignment-detail_29 | [^<U+000A>] \n",
      "assessment-detail_30 ::= [^<U+000A>] assessment-detail_30 | [^<U+000A>] \n",
      "accuracy-detail_31 ::= [^<U+000A>] accuracy-detail_31 | [^<U+000A>] \n",
      "root ::= analyze-step understand-step identify-step plan-revised-step [<U+000A>] \n",
      "analyze-step ::= [S] [t] [e] [p] [ ] analyze-step_5 [0-9] [.] [ ] [A] [n] [a] [l] [y] [z] [e] [ ] [t] [h] [e] [ ] [T] [e] [x] [t] [:] analyze-step_6 [<U+000A>] \n",
      "understand-step ::= [S] [t] [e] [p] [ ] understand-step_7 [0-9] [.] [ ] [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] [ ] [t] [h] [e] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [:] understand-step_8 [<U+000A>] \n",
      "identify-step ::= [S] [t] [e] [p] [ ] identify-step_9 [0-9] [.] [ ] [I] [d] [e] [n] [t] [i] [f] [y] [ ] [F] [l] [a] [w] [e] [d] [ ] [P] [a] [r] [t] [ ] [o] [f] [ ] [t] [h] [e] [ ] [A] [n] [s] [w] [e] [r] [:] identify-step_10 [<U+000A>] \n",
      "plan-revised-step ::= [S] [t] [e] [p] [ ] plan-revised-step_11 [0-9] [.] [ ] [P] [l] [a] [n] [ ] [R] [e] [v] [i] [s] [e] [d] [ ] [A] [n] [s] [w] [e] [r] [:] plan-revised-step_12 [<U+000A>] \n",
      "analyze-step_5 ::= [0-9] | \n",
      "analyze-step_6 ::= [^<U+000A>] analyze-step_6 | [^<U+000A>] \n",
      "understand-step_7 ::= [0-9] | \n",
      "understand-step_8 ::= [^<U+000A>] understand-step_8 | [^<U+000A>] \n",
      "identify-step_9 ::= [0-9] | \n",
      "identify-step_10 ::= [^<U+000A>] identify-step_10 | [^<U+000A>] \n",
      "plan-revised-step_11 ::= [0-9] | \n",
      "plan-revised-step_12 ::= [^<U+000A>] plan-revised-step_12 | [^<U+000A>] \n",
      "root ::= deep-analysis [<U+000A>] comprehensive-understanding [<U+000A>] targeted-comparison [<U+000A>] identification-of-extraneous-info [<U+000A>] final-judgment \n",
      "deep-analysis ::= [#] [#] [#] [ ] [D] [e] [e] [p] [ ] [A] [n] [a] [l] [y] [s] [i] [s] [ ] [o] [f] [ ] [t] [h] [e] [ ] [T] [e] [x] [t] [:] [<U+000A>] content-scope-and-detail type-of-information \n",
      "comprehensive-understanding ::= [#] [#] [#] [ ] [C] [o] [m] [p] [r] [e] [h] [e] [n] [s] [i] [v] [e] [ ] [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] [i] [n] [g] [ ] [o] [f] [ ] [t] [h] [e] [ ] [A] [n] [s] [w] [e] [r] [:] [<U+000A>] key-components-identification depth-of-explanation \n",
      "targeted-comparison ::= [#] [#] [#] [ ] [T] [a] [r] [g] [e] [t] [e] [d] [ ] [C] [o] [m] [p] [a] [r] [i] [s] [o] [n] [ ] [o] [f] [ ] [A] [n] [s] [w] [e] [r] [ ] [w] [i] [t] [h] [ ] [T] [e] [x] [t] [:] [<U+000A>] content-alignment depth-alignment \n",
      "identification-of-extraneous-info ::= [#] [#] [#] [ ] [I] [d] [e] [n] [t] [i] [f] [i] [c] [a] [t] [i] [o] [n] [ ] [o] [f] [ ] [E] [x] [t] [r] [a] [n] [e] [o] [u] [s] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [:] [<U+000A>] spotting-additional-details assessing-impact \n",
      "final-judgment ::= [#] [#] [#] [ ] [F] [i] [n] [a] [l] [ ] [J] [u] [d] [g] [m] [e] [n] [t] [ ] [o] [n] [ ] [A] [n] [s] [w] [e] [r] [ ] [R] [e] [l] [e] [v] [a] [n] [c] [e] [:] [<U+000A>] relevance-assessment explanation-of-judgment \n",
      "content-scope-and-detail ::= [#] [#] [#] [#] [ ] [C] [o] [n] [t] [e] [n] [t] [ ] [S] [c] [o] [p] [e] [ ] [a] [n] [d] [ ] [D] [e] [t] [a] [i] [l] [:] [ ] text-detail [<U+000A>] \n",
      "type-of-information ::= [#] [#] [#] [#] [ ] [T] [y] [p] [e] [ ] [o] [f] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [:] [ ] info-type [<U+000A>] \n",
      "text-detail ::= text-detail_26 \n",
      "info-type ::= info-type_27 \n",
      "key-components-identification ::= [#] [#] [#] [#] [ ] [K] [e] [y] [ ] [C] [o] [m] [p] [o] [n] [e] [n] [t] [s] [ ] [I] [d] [e] [n] [t] [i] [f] [i] [c] [a] [t] [i] [o] [n] [:] [ ] components-detail [<U+000A>] \n",
      "depth-of-explanation ::= [#] [#] [#] [#] [ ] [D] [e] [p] [t] [h] [ ] [o] [f] [ ] [E] [x] [p] [l] [a] [n] [a] [t] [i] [o] [n] [:] [ ] explanation-detail [<U+000A>] \n",
      "components-detail ::= components-detail_28 \n",
      "explanation-detail ::= explanation-detail_29 \n",
      "content-alignment ::= [#] [#] [#] [#] [ ] [C] [o] [n] [t] [e] [n] [t] [ ] [A] [l] [i] [g] [n] [m] [e] [n] [t] [:] [ ] alignment-detail [<U+000A>] \n",
      "depth-alignment ::= [#] [#] [#] [#] [ ] [D] [e] [p] [t] [h] [ ] [A] [l] [i] [g] [n] [m] [e] [n] [t] [:] [ ] depth-detail [<U+000A>] \n",
      "alignment-detail ::= alignment-detail_30 \n",
      "depth-detail ::= depth-detail_31 \n",
      "spotting-additional-details ::= [#] [#] [#] [#] [ ] [S] [p] [o] [t] [t] [i] [n] [g] [ ] [A] [d] [d] [i] [t] [i] [o] [n] [a] [l] [ ] [D] [e] [t] [a] [i] [l] [s] [:] [ ] additional-details [<U+000A>] \n",
      "assessing-impact ::= [#] [#] [#] [#] [ ] [A] [s] [s] [e] [s] [s] [i] [n] [g] [ ] [I] [m] [p] [a] [c] [t] [ ] [o] [f] [ ] [A] [d] [d] [i] [t] [i] [o] [n] [a] [l] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [:] [ ] impact-assessment [<U+000A>] \n",
      "additional-details ::= additional-details_32 \n",
      "impact-assessment ::= impact-assessment_33 \n",
      "relevance-assessment ::= [#] [#] [#] [#] [ ] [R] [e] [l] [e] [v] [a] [n] [c] [e] [ ] [A] [s] [s] [e] [s] [s] [m] [e] [n] [t] [:] [ ] relevance-detail [<U+000A>] \n",
      "explanation-of-judgment ::= [#] [#] [#] [#] [ ] [E] [x] [p] [l] [a] [n] [a] [t] [i] [o] [n] [ ] [o] [f] [ ] [J] [u] [d] [g] [m] [e] [n] [t] [:] [ ] judgment-detail [<U+000A>] \n",
      "relevance-detail ::= relevance-detail_34 \n",
      "judgment-detail ::= judgment-detail_35 \n",
      "text-detail_26 ::= [^<U+000A>] text-detail_26 | [^<U+000A>] \n",
      "info-type_27 ::= [^<U+000A>] info-type_27 | [^<U+000A>] \n",
      "components-detail_28 ::= [^<U+000A>] components-detail_28 | [^<U+000A>] \n",
      "explanation-detail_29 ::= [^<U+000A>] explanation-detail_29 | [^<U+000A>] \n",
      "alignment-detail_30 ::= [^<U+000A>] alignment-detail_30 | [^<U+000A>] \n",
      "depth-detail_31 ::= [^<U+000A>] depth-detail_31 | [^<U+000A>] \n",
      "additional-details_32 ::= [^<U+000A>] additional-details_32 | [^<U+000A>] \n",
      "impact-assessment_33 ::= [^<U+000A>] impact-assessment_33 | [^<U+000A>] \n",
      "relevance-detail_34 ::= [^<U+000A>] relevance-detail_34 | [^<U+000A>] \n",
      "judgment-detail_35 ::= [^<U+000A>] judgment-detail_35 | [^<U+000A>] \n",
      "root ::= name [<U+000A>] [T] [r] [a] [i] [t] [s] [:] [ ] traits [<U+000A>] [<U+000A>] [D] [i] [a] [l] [o] [g] [u] [e] [ ] [E] [x] [a] [m] [p] [l] [e] [s] [:] dialogue-examples \n",
      "name ::= name_4 \n",
      "traits ::= trait trait trait trait trait trait trait trait trait trait trait trait traits_6 traits_7 traits_8 traits_9 traits_10 traits_11 traits_12 traits_13 \n",
      "dialogue-examples ::= history personality \n",
      "name_4 ::= [^<U+000A> ] name_4 | [^<U+000A> ] \n",
      "trait ::= [A-Z] trait_14 [,] [ ] \n",
      "traits_6 ::= trait | \n",
      "traits_7 ::= trait | \n",
      "traits_8 ::= trait | \n",
      "traits_9 ::= trait | \n",
      "traits_10 ::= trait | \n",
      "traits_11 ::= trait | \n",
      "traits_12 ::= trait | \n",
      "traits_13 ::= trait | \n",
      "trait_14 ::= [a-z '] trait_14 | [a-z '] \n",
      "history ::= [<U+000A>] [S] [t] [r] [a] [n] [g] [e] [r] [:] [ ] [\"] [W] [h] [a] [t] ['] [s] [ ] [y] [o] [u] [r] [ ] [b] [a] [c] [k] [s] [t] [o] [r] [y] [?] [\"] [<U+000A>] name [:] [ ] [\"] history_17 \n",
      "personality ::= [<U+000A>] [S] [t] [r] [a] [n] [g] [e] [r] [:] [ ] [\"] [W] [h] [a] [t] ['] [s] [ ] [y] [o] [u] [r] [ ] [p] [e] [r] [s] [o] [n] [a] [l] [i] [t] [y] [?] [\"] [<U+000A>] name [:] [ ] [\"] personality_18 \n",
      "history_17 ::= [^<U+000A>] history_17 | [^<U+000A>] \n",
      "personality_18 ::= [^<U+000A>] personality_18 | [^<U+000A>] \n",
      "root ::= question-validation [<U+000A>] answer-validation [<U+000A>] critical-evaluation [<U+000A>] revised-qatuple \n",
      "question-validation ::= [#] [#] [#] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [ ] [C] [o] [n] [t] [e] [x] [t] [ ] [V] [a] [l] [i] [d] [a] [t] [i] [o] [n] [<U+000A>] special-term-check-question text-and-author-specificity scope-and-precision \n",
      "answer-validation ::= [#] [#] [#] [ ] [A] [n] [s] [w] [e] [r] [ ] [C] [o] [n] [t] [e] [x] [t] [ ] [V] [a] [l] [i] [d] [a] [t] [i] [o] [n] [:] [<U+000A>] special-term-check-answer specificity-and-clarity answer-only-context-issues \n",
      "critical-evaluation ::= [#] [#] [#] [ ] [C] [r] [i] [t] [i] [c] [a] [l] [ ] [E] [v] [a] [l] [u] [a] [t] [i] [o] [n] [ ] [a] [n] [d] [ ] [F] [i] [n] [a] [l] [ ] [J] [u] [d] [g] [m] [e] [n] [t] [:] [<U+000A>] evaluation final-judgment \n",
      "revised-qatuple ::= [#] [#] [#] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [ ] [R] [e] [w] [o] [r] [d] [i] [n] [g] [ ] [(] [u] [s] [i] [n] [g] [ ] [t] [e] [x] [t] [ ] [d] [e] [t] [a] [i] [l] [s] [ ] [a] [s] [ ] [r] [e] [f] [e] [r] [e] [n] [c] [e] [)] [:] [<U+000A>] revised-question-answer \n",
      "special-term-check-question ::= [#] [#] [#] [#] [ ] [S] [p] [e] [c] [i] [a] [l] [ ] [T] [e] [r] [m] [ ] [C] [o] [n] [t] [e] [x] [t] [ ] [C] [h] [e] [c] [k] [:] [ ] [S] [p] [e] [c] [i] [f] [i] [c] [a] [l] [l] [y] [ ] [c] [h] [e] [c] [k] [ ] [f] [o] [r] [ ] [u] [s] [e] [ ] [o] [f] [ ] [t] [h] [e] [ ] [t] [e] [r] [m] [s] [ ] [\"] [b] [o] [o] [k] [\"] [,] [ ] [\"] [t] [e] [x] [t] [\"] [,] [ ] [\"] [p] [a] [s] [s] [a] [g] [e] [\"] [,] [ ] [a] [n] [d] [ ] [\"] [e] [x] [c] [e] [r] [p] [t] [\"] [ ] [w] [i] [t] [h] [o] [u] [t] [ ] [c] [o] [n] [t] [e] [x] [t] [ ] [a] [b] [o] [u] [t] [ ] [w] [h] [i] [c] [h] [ ] [s] [p] [e] [c] [i] [f] [i] [c] [ ] [t] [h] [i] [n] [g] [ ] [i] [s] [ ] [b] [e] [i] [n] [g] [ ] [d] [i] [s] [c] [u] [s] [s] [e] [d] [.] [ ] question-term-detail [<U+000A>] \n",
      "text-and-author-specificity ::= [#] [#] [#] [#] [ ] [T] [e] [x] [t] [ ] [a] [n] [d] [ ] [A] [u] [t] [h] [o] [r] [ ] [S] [p] [e] [c] [i] [f] [i] [c] [i] [t] [y] [:] [ ] question-text-author-detail [<U+000A>] \n",
      "scope-and-precision ::= [#] [#] [#] [#] [ ] [S] [c] [o] [p] [e] [ ] [a] [n] [d] [ ] [P] [r] [e] [c] [i] [s] [i] [o] [n] [:] [ ] question-scope-detail [<U+000A>] \n",
      "question-term-detail ::= question-term-detail_22 \n",
      "question-text-author-detail ::= question-text-author-detail_23 \n",
      "question-scope-detail ::= question-scope-detail_24 \n",
      "special-term-check-answer ::= [#] [#] [#] [#] [ ] [S] [p] [e] [c] [i] [a] [l] [ ] [T] [e] [r] [m] [ ] [C] [o] [n] [t] [e] [x] [t] [ ] [C] [h] [e] [c] [k] [:] [ ] [S] [p] [e] [c] [i] [f] [i] [c] [a] [l] [l] [y] [ ] [c] [h] [e] [c] [k] [ ] [f] [o] [r] [ ] [u] [s] [e] [ ] [o] [f] [ ] [t] [h] [e] [ ] [t] [e] [r] [m] [s] [ ] [\"] [b] [o] [o] [k] [\"] [,] [ ] [\"] [t] [e] [x] [t] [\"] [,] [ ] [\"] [p] [a] [s] [s] [a] [g] [e] [\"] [,] [ ] [a] [n] [d] [ ] [\"] [e] [x] [c] [e] [r] [p] [t] [\"] [ ] [w] [i] [t] [h] [o] [u] [t] [ ] [c] [o] [n] [t] [e] [x] [t] [ ] [a] [b] [o] [u] [t] [ ] [w] [h] [i] [c] [h] [ ] [s] [p] [e] [c] [i] [f] [i] [c] [ ] [t] [h] [i] [n] [g] [ ] [i] [s] [ ] [b] [e] [i] [n] [g] [ ] [d] [i] [s] [c] [u] [s] [s] [e] [d] [.] [ ] answer-term-detail [<U+000A>] \n",
      "specificity-and-clarity ::= [#] [#] [#] [#] [ ] [S] [p] [e] [c] [i] [f] [i] [c] [i] [t] [y] [ ] [a] [n] [d] [ ] [C] [l] [a] [r] [i] [t] [y] [:] [ ] answer-specificity-detail [<U+000A>] \n",
      "answer-only-context-issues ::= [#] [#] [#] [#] [ ] [A] [n] [s] [w] [e] [r] [-] [O] [n] [l] [y] [ ] [C] [o] [n] [t] [e] [x] [t] [ ] [I] [s] [s] [u] [e] [s] [:] [ ] answer-context-issue-detail [<U+000A>] \n",
      "answer-term-detail ::= answer-term-detail_25 \n",
      "answer-specificity-detail ::= answer-specificity-detail_26 \n",
      "answer-context-issue-detail ::= answer-context-issue-detail_27 \n",
      "evaluation ::= [#] [#] [#] [#] [ ] [E] [v] [a] [l] [u] [a] [t] [i] [o] [n] [:] [ ] evaluation-detail [<U+000A>] \n",
      "final-judgment ::= [#] [#] [#] [#] [ ] [F] [i] [n] [a] [l] [ ] [j] [u] [d] [g] [m] [e] [n] [t] [:] [ ] judgment-detail [<U+000A>] \n",
      "evaluation-detail ::= evaluation-detail_28 \n",
      "judgment-detail ::= judgment-detail_29 \n",
      "revised-question-answer ::= [Q] [u] [e] [s] [t] [i] [o] [n] [:] [ ] revised-question-answer_30 [<U+000A>] [A] [n] [s] [w] [e] [r] [:] [ ] revised-question-answer_31 [<U+000A>] \n",
      "question-term-detail_22 ::= [^<U+000A>] question-term-detail_22 | [^<U+000A>] \n",
      "question-text-author-detail_23 ::= [^<U+000A>] question-text-author-detail_23 | [^<U+000A>] \n",
      "question-scope-detail_24 ::= [^<U+000A>] question-scope-detail_24 | [^<U+000A>] \n",
      "answer-term-detail_25 ::= [^<U+000A>] answer-term-detail_25 | [^<U+000A>] \n",
      "answer-specificity-detail_26 ::= [^<U+000A>] answer-specificity-detail_26 | [^<U+000A>] \n",
      "answer-context-issue-detail_27 ::= [^<U+000A>] answer-context-issue-detail_27 | [^<U+000A>] \n",
      "evaluation-detail_28 ::= [^<U+000A>] evaluation-detail_28 | [^<U+000A>] \n",
      "judgment-detail_29 ::= [P] [a] [s] [s] [.] | [F] [a] [i] [l] [.] | [R] [e] [w] [o] [r] [d] [.] \n",
      "revised-question-answer_30 ::= [^<U+000A>] revised-question-answer_30 | [^<U+000A>] \n",
      "revised-question-answer_31 ::= [^<U+000A>] revised-question-answer_31 | [^<U+000A>] \n",
      "root ::= [Q] [u] [e] [s] [t] [i] [o] [n] [:] [ ] root_1 [<U+000A>] [A] [n] [s] [w] [e] [r] [:] [ ] root_2 [<U+000A>] \n",
      "root_1 ::= [^<U+000A>] root_1 | [^<U+000A>] \n",
      "root_2 ::= [^<U+000A>] root_2 | [^<U+000A>] \n",
      "root ::= root_1 [<U+000A>] \n",
      "root_1 ::= [^<U+000A>] root_1 | [^<U+000A>] \n",
      "root ::= understand-question-step compare-question-step understand-answer-step compare-step final-step [<U+000A>] \n",
      "understand-question-step ::= [S] [t] [e] [p] [ ] understand-question-step_6 [0-9] [.] [ ] [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] [ ] [t] [h] [e] [ ] [p] [r] [o] [v] [i] [d] [e] [d] [ ] [q] [u] [e] [s] [t] [i] [o] [n] [:] understand-question-step_7 [<U+000A>] \n",
      "compare-question-step ::= [S] [t] [e] [p] [ ] compare-question-step_8 [0-9] [.] [ ] [C] [o] [m] [p] [a] [r] [e] [ ] [t] [h] [e] [ ] [c] [o] [n] [v] [e] [r] [s] [a] [t] [i] [o] [n] ['] [s] [ ] [q] [u] [e] [s] [t] [i] [o] [n] [:] [ ] compare-question-step_9 [<U+000A>] \n",
      "understand-answer-step ::= [S] [t] [e] [p] [ ] understand-answer-step_10 [0-9] [.] [ ] [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] [ ] [t] [h] [e] [ ] [p] [r] [o] [v] [i] [d] [e] [d] [ ] [a] [n] [s] [w] [e] [r] [:] understand-answer-step_11 [<U+000A>] \n",
      "compare-step ::= [S] [t] [e] [p] [ ] compare-step_12 [0-9] [.] [ ] [C] [o] [m] [p] [a] [r] [e] [ ] [t] [h] [e] [ ] [c] [o] [n] [v] [e] [r] [s] [a] [t] [i] [o] [n] ['] [s] [ ] [a] [n] [s] [w] [e] [r] [:] compare-step_13 [<U+000A>] \n",
      "final-step ::= [S] [t] [e] [p] [ ] final-step_14 [0-9] [.] [ ] [F] [i] [n] [a] [l] [ ] [J] [u] [d] [g] [e] [m] [e] [n] [t] [:] [ ] final-step_15 [<U+000A>] \n",
      "understand-question-step_6 ::= [0-9] | \n",
      "understand-question-step_7 ::= [^<U+000A>] understand-question-step_7 | [^<U+000A>] \n",
      "compare-question-step_8 ::= [0-9] | \n",
      "compare-question-step_9 ::= [^<U+000A>] compare-question-step_9 | [^<U+000A>] \n",
      "understand-answer-step_10 ::= [0-9] | \n",
      "understand-answer-step_11 ::= [^<U+000A>] understand-answer-step_11 | [^<U+000A>] \n",
      "compare-step_12 ::= [0-9] | \n",
      "compare-step_13 ::= [^<U+000A>] compare-step_13 | [^<U+000A>] \n",
      "final-step_14 ::= [0-9] | \n",
      "final-step_15 ::= [I] [n] [c] [o] [n] [s] [i] [s] [t] [e] [n] [t] | [C] [o] [n] [s] [i] [s] [t] [e] [n] [t] \n",
      "root ::= sequential-matching-section accuracy-check-section conclusion-section \n",
      "sequential-matching-section ::= [#] [#] [ ] [S] [e] [q] [u] [e] [n] [t] [i] [a] [l] [ ] [M] [a] [t] [c] [h] [i] [n] [g] [ ] [o] [f] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [s] [ ] [i] [n] [ ] [t] [h] [e] [ ] [C] [o] [n] [v] [e] [r] [s] [a] [t] [i] [o] [n] [:] [<U+000A>] [#] [#] [#] [ ] [S] [e] [q] [u] [e] [n] [c] [e] [ ] [a] [n] [d] [ ] [P] [h] [r] [a] [s] [i] [n] [g] [ ] [o] [f] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [s] [:] [<U+000A>] sequential-matching-section_5 \n",
      "accuracy-check-section ::= [#] [#] [ ] [A] [c] [c] [u] [r] [a] [c] [y] [ ] [C] [h] [e] [c] [k] [ ] [f] [o] [r] [ ] [A] [n] [s] [w] [e] [r] [s] [ ] [i] [n] [ ] [t] [h] [e] [ ] [C] [o] [n] [v] [e] [r] [s] [a] [t] [i] [o] [n] [:] [<U+000A>] [#] [#] [#] [ ] [M] [a] [t] [c] [h] [i] [n] [g] [ ] [A] [n] [s] [w] [e] [r] [s] [ ] [w] [i] [t] [h] [ ] [P] [r] [o] [v] [i] [d] [e] [d] [ ] [C] [o] [n] [t] [e] [n] [t] [:] [<U+000A>] accuracy-check-section_7 \n",
      "conclusion-section ::= [#] [#] [ ] [C] [o] [n] [c] [l] [u] [s] [i] [o] [n] [:] [<U+000A>] conclusion-section_9 \n",
      "matching-statement ::= number [.] [ ] matching-statement_11 [<U+000A>] \n",
      "sequential-matching-section_5 ::= matching-statement sequential-matching-section_5 | matching-statement \n",
      "accuracy-statement ::= number [.] [ ] accuracy-statement_12 [<U+000A>] \n",
      "accuracy-check-section_7 ::= accuracy-statement accuracy-check-section_7 | accuracy-statement \n",
      "conclusion-statement ::= [ ] [ ] [-] [ ] conclusion-statement_13 [<U+000A>] \n",
      "conclusion-section_9 ::= conclusion-statement conclusion-section_9 | conclusion-statement \n",
      "number ::= [1-9] \n",
      "matching-statement_11 ::= [^<U+000A>] matching-statement_11 | [^<U+000A>] \n",
      "accuracy-statement_12 ::= [^<U+000A>] accuracy-statement_12 | [^<U+000A>] \n",
      "conclusion-statement_13 ::= [^<U+000A>] conclusion-statement_13 | [^<U+000A>] \n",
      "final-judgement ::= [ ] [ ] [-] [ ] [F] [i] [n] [a] [l] [ ] [J] [u] [d] [g] [m] [e] [n] [t] [:] final-judgement_15 \n",
      "final-judgement_15 ::= [^<U+000A>] final-judgement_15 | [^<U+000A>] \n",
      "root ::= normalization-block core-components-block comparative-analysis-block criteria-block conclusion-block \n",
      "normalization-block ::= [#] [#] [ ] [N] [o] [r] [m] [a] [l] [i] [z] [a] [t] [i] [o] [n] [ ] [o] [f] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [s] [:] [<U+000A>] normalization-block_7 \n",
      "core-components-block ::= [#] [#] [ ] [I] [d] [e] [n] [t] [i] [f] [i] [c] [a] [t] [i] [o] [n] [ ] [o] [f] [ ] [C] [o] [r] [e] [ ] [C] [o] [m] [p] [o] [n] [e] [n] [t] [s] [:] [<U+000A>] [#] [#] [#] [ ] [S] [u] [b] [j] [e] [c] [t] [ ] [M] [a] [t] [t] [e] [r] [:] [<U+000A>] core-components-block_10 [#] [#] [#] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [ ] [S] [o] [u] [g] [h] [t] [:] [<U+000A>] core-components-block_12 \n",
      "comparative-analysis-block ::= [#] [#] [ ] [C] [o] [m] [p] [a] [r] [a] [t] [i] [v] [e] [ ] [A] [n] [a] [l] [y] [s] [i] [s] [ ] [A] [c] [r] [o] [s] [s] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [s] [:] [<U+000A>] [#] [#] [#] [ ] [D] [i] [r] [e] [c] [t] [ ] [C] [o] [m] [p] [a] [r] [i] [s] [o] [n] [:] [<U+000A>] comparative-analysis-block_17 [#] [#] [#] [ ] [O] [v] [e] [r] [l] [a] [p] [ ] [i] [n] [ ] [C] [o] [r] [e] [ ] [C] [o] [m] [p] [o] [n] [e] [n] [t] [s] [:] [<U+000A>] comparative-analysis-block_18 [<U+000A>] \n",
      "criteria-block ::= [#] [#] [ ] [C] [r] [i] [t] [e] [r] [i] [a] [ ] [f] [o] [r] [ ] [D] [u] [p] [l] [i] [c] [a] [t] [i] [o] [n] [:] [<U+000A>] [#] [#] [#] [ ] [E] [x] [a] [c] [t] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [ ] [M] [a] [t] [c] [h] [:] [<U+000A>] content [#] [#] [#] [ ] [N] [e] [g] [a] [t] [i] [o] [n] [ ] [o] [f] [ ] [M] [i] [n] [o] [r] [ ] [D] [i] [f] [f] [e] [r] [e] [n] [c] [e] [s] [:] [<U+000A>] content [<U+000A>] \n",
      "conclusion-block ::= [#] [#] [ ] [C] [o] [n] [c] [l] [u] [s] [i] [o] [n] [ ] [a] [n] [d] [ ] [L] [a] [b] [e] [l] [i] [n] [g] [:] [<U+000A>] content [<U+000A>] [<U+000A>] [#] [#] [ ] [U] [n] [i] [q] [u] [e] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [s] [:] [ ] unique-questions [<U+000A>] \n",
      "normalized-question ::= [-] [ ] [\"] content [\"] [<U+000A>] [ ] [ ] [-] [ ] [N] [o] [r] [m] [a] [l] [i] [z] [e] [d] [:] [ ] content [<U+000A>] \n",
      "normalization-block_7 ::= normalized-question normalization-block_7 | normalized-question \n",
      "content ::= content_25 \n",
      "subject-matter ::= [-] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [ ] subject-matter_14 [:] [ ] content [<U+000A>] \n",
      "core-components-block_10 ::= subject-matter core-components-block_10 | subject-matter \n",
      "information-sought ::= [-] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [ ] information-sought_15 [:] [ ] content [<U+000A>] \n",
      "core-components-block_12 ::= information-sought core-components-block_12 | information-sought \n",
      "digit ::= [0-9] \n",
      "subject-matter_14 ::= digit subject-matter_14 | digit \n",
      "information-sought_15 ::= digit information-sought_15 | digit \n",
      "bullet-item ::= [-] [ ] content [<U+000A>] \n",
      "comparative-analysis-block_17 ::= bullet-item comparative-analysis-block_17 | bullet-item \n",
      "comparative-analysis-block_18 ::= bullet-item comparative-analysis-block_18 | bullet-item \n",
      "unique-questions ::= [[] unique-questions_20 unique-questions_23 []] \n",
      "unique-questions_20 ::= digit unique-questions_20 | digit \n",
      "unique-questions_21 ::= [,] [ ] unique-questions_22 \n",
      "unique-questions_22 ::= digit unique-questions_22 | digit \n",
      "unique-questions_23 ::= unique-questions_21 unique-questions_23 | \n",
      "char ::= [^<U+000A>] \n",
      "content_25 ::= char content_25 | char \n",
      "root ::= identify-content-step evaluate-relevance-step assess-contexts-and-formats-step assess-possibility-step determine-suitability-step check-contextual-completeness-step final-step [<U+000A>] \n",
      "identify-content-step ::= [S] [t] [e] [p] [ ] identify-content-step_8 [0-9] [.] [ ] [I] [d] [e] [n] [t] [i] [f] [y] [ ] [P] [a] [r] [a] [g] [r] [a] [p] [h] [ ] [C] [o] [n] [t] [e] [n] [t] [:] [ ] identify-content-step_9 [<U+000A>] \n",
      "evaluate-relevance-step ::= [S] [t] [e] [p] [ ] evaluate-relevance-step_10 [0-9] [.] [ ] [E] [v] [a] [l] [u] [a] [t] [e] [ ] [E] [d] [u] [c] [a] [t] [i] [o] [n] [a] [l] [ ] [R] [e] [l] [e] [v] [a] [n] [c] [e] [:] [ ] evaluate-relevance-step_11 [<U+000A>] \n",
      "assess-contexts-and-formats-step ::= [S] [t] [e] [p] [ ] assess-contexts-and-formats-step_12 [0-9] [.] [ ] [A] [s] [s] [e] [s] [s] [ ] [S] [p] [e] [c] [i] [f] [i] [c] [ ] [C] [o] [n] [t] [e] [x] [t] [s] [ ] [a] [n] [d] [ ] [F] [o] [r] [m] [a] [t] [s] [:] [<U+000A>] context-format-bullets \n",
      "assess-possibility-step ::= [S] [t] [e] [p] [ ] assess-possibility-step_14 [0-9] [.] [ ] [A] [s] [s] [e] [s] [s] [ ] [t] [h] [e] [ ] [P] [o] [s] [s] [i] [b] [i] [l] [i] [t] [y] [ ] [o] [f] [ ] [F] [o] [r] [m] [u] [l] [a] [t] [i] [n] [g] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [s] [:] [ ] assess-possibility-step_15 [<U+000A>] \n",
      "determine-suitability-step ::= [S] [t] [e] [p] [ ] determine-suitability-step_16 [0-9] [.] [ ] [D] [e] [t] [e] [r] [m] [i] [n] [e] [ ] [S] [u] [i] [t] [a] [b] [i] [l] [i] [t] [y] [ ] [f] [o] [r] [ ] [E] [d] [u] [c] [a] [t] [i] [o] [n] [a] [l] [ ] [P] [u] [r] [p] [o] [s] [e] [s] [:] [ ] determine-suitability-step_17 [<U+000A>] \n",
      "check-contextual-completeness-step ::= [S] [t] [e] [p] [ ] check-contextual-completeness-step_18 [0-9] [.] [ ] [C] [h] [e] [c] [k] [ ] [f] [o] [r] [ ] [C] [o] [n] [t] [e] [x] [t] [u] [a] [l] [ ] [C] [o] [m] [p] [l] [e] [t] [e] [n] [e] [s] [s] [:] [ ] check-contextual-completeness-step_19 [<U+000A>] \n",
      "final-step ::= [S] [t] [e] [p] [ ] final-step_20 [0-9] [.] [ ] [F] [i] [n] [a] [l] [ ] [J] [u] [d] [g] [m] [e] [n] [t] [:] [ ] final-step_21 [<U+000A>] \n",
      "identify-content-step_8 ::= [0-9] | \n",
      "identify-content-step_9 ::= [^<U+000A>] identify-content-step_9 | [^<U+000A>] \n",
      "evaluate-relevance-step_10 ::= [0-9] | \n",
      "evaluate-relevance-step_11 ::= [^<U+000A>] evaluate-relevance-step_11 | [^<U+000A>] \n",
      "assess-contexts-and-formats-step_12 ::= [0-9] | \n",
      "context-format-bullets ::= context-format-bullets_23 \n",
      "assess-possibility-step_14 ::= [0-9] | \n",
      "assess-possibility-step_15 ::= [^<U+000A>] assess-possibility-step_15 | [^<U+000A>] \n",
      "determine-suitability-step_16 ::= [0-9] | \n",
      "determine-suitability-step_17 ::= [^<U+000A>] determine-suitability-step_17 | [^<U+000A>] \n",
      "check-contextual-completeness-step_18 ::= [0-9] | \n",
      "check-contextual-completeness-step_19 ::= [^<U+000A>] check-contextual-completeness-step_19 | [^<U+000A>] \n",
      "final-step_20 ::= [0-9] | \n",
      "final-step_21 ::= [U] [n] [s] [u] [i] [t] [a] [b] [l] [e] | [S] [u] [i] [t] [a] [b] [l] [e] | [s] [u] [i] [t] [a] [b] [l] [e] | [u] [n] [s] [u] [i] [t] [a] [b] [l] [e] \n",
      "bullet-item ::= [ ] [ ] [-] [ ] bullet-item-detail [<U+000A>] \n",
      "context-format-bullets_23 ::= bullet-item context-format-bullets_23 | bullet-item \n",
      "bullet-item-detail ::= bullet-item-detail_25 \n",
      "bullet-item-detail_25 ::= [^<U+000A>] bullet-item-detail_25 | [^<U+000A>] \n",
      "root ::= analyze-step understand-step identify-step plan-step \n",
      "analyze-step ::= [S] [t] [e] [p] [ ] analyze-step_5 [0-9] [.] [ ] [A] [n] [a] [l] [y] [z] [e] [ ] [t] [h] [e] [ ] [T] [e] [x] [t] [:] analyze-step_6 [<U+000A>] \n",
      "understand-step ::= [S] [t] [e] [p] [ ] understand-step_7 [0-9] [.] [ ] [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] [ ] [t] [h] [e] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [:] understand-step_8 [<U+000A>] \n",
      "identify-step ::= [S] [t] [e] [p] [ ] identify-step_9 [0-9] [.] [ ] [I] [d] [e] [n] [t] [i] [f] [y] [ ] [t] [h] [e] [ ] [I] [n] [c] [o] [r] [r] [e] [c] [t] [ ] [P] [a] [r] [t] [ ] [o] [f] [ ] [t] [h] [e] [ ] [A] [n] [s] [w] [e] [r] [:] identify-step_10 [<U+000A>] \n",
      "plan-step ::= [S] [t] [e] [p] [ ] plan-step_11 [0-9] [.] [ ] [P] [l] [a] [n] [ ] [a] [ ] [C] [o] [r] [r] [e] [c] [t] [e] [d] [ ] [A] [n] [s] [w] [e] [r] [:] plan-step_12 [<U+000A>] \n",
      "analyze-step_5 ::= [0-9] | \n",
      "analyze-step_6 ::= [^<U+000A>] analyze-step_6 | [^<U+000A>] \n",
      "understand-step_7 ::= [0-9] | \n",
      "understand-step_8 ::= [^<U+000A>] understand-step_8 | [^<U+000A>] \n",
      "identify-step_9 ::= [0-9] | \n",
      "identify-step_10 ::= [^<U+000A>] identify-step_10 | [^<U+000A>] \n",
      "plan-step_11 ::= [0-9] | \n",
      "plan-step_12 ::= [^<U+000A>] plan-step_12 | [^<U+000A>] \n",
      "root ::= analyze-step identify-step generate-step refine-step ensure-step end-of-reasoning \n",
      "analyze-step ::= [S] [t] [e] [p] [ ] analyze-step_11 [0-9] [.] [ ] [A] [n] [a] [l] [y] [z] [e] [ ] [t] [h] [e] [ ] [R] [e] [a] [s] [o] [n] [ ] [f] [o] [r] [ ] [t] [h] [e] [ ] [F] [l] [a] [w] [:] analyze-step_12 [<U+000A>] \n",
      "identify-step ::= [S] [t] [e] [p] [ ] identify-step_13 [0-9] [.] [ ] [I] [d] [e] [n] [t] [i] [f] [y] [ ] [K] [e] [y] [ ] [C] [o] [n] [c] [e] [p] [t] [s] [ ] [i] [n] [ ] [P] [a] [r] [a] [g] [r] [a] [p] [h] [s] [:] identify-step_14 [<U+000A>] \n",
      "generate-step ::= [S] [t] [e] [p] [ ] generate-step_15 [0-9] [.] [ ] [G] [e] [n] [e] [r] [a] [t] [e] [ ] [a] [ ] [N] [e] [w] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [ ] [I] [d] [e] [a] [:] generate-step_16 [<U+000A>] \n",
      "refine-step ::= [S] [t] [e] [p] [ ] refine-step_17 [0-9] [.] [ ] [R] [e] [f] [i] [n] [e] [ ] [t] [h] [e] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [:] refine-step_18 [<U+000A>] \n",
      "ensure-step ::= [S] [t] [e] [p] [ ] ensure-step_19 [0-9] [.] [ ] [E] [n] [s] [u] [r] [e] [ ] [A] [l] [i] [g] [n] [m] [e] [n] [t] [ ] [w] [i] [t] [h] [ ] [T] [e] [x] [t] [:] ensure-step_20 [<U+000A>] \n",
      "end-of-reasoning ::= [S] [t] [e] [p] [ ] end-of-reasoning_21 [0-9] [.] [ ] [E] [n] [d] end-of-reasoning_22 [<U+000A>] \n",
      "step ::= [S] [t] [e] [p] [ ] step_8 [0-9] [.] [ ] step_9 step_10 [<U+000A>] \n",
      "step_8 ::= [0-9] | \n",
      "step_9 ::= [A] [n] [a] [l] [y] [z] [e] | [I] [d] [e] [n] [t] [i] [f] [y] | [G] [e] [n] [e] [r] [a] [t] [e] | [R] [e] [f] [i] [n] [e] | [E] [n] [s] [u] [r] [e] \n",
      "step_10 ::= [^<U+000A>] step_10 | [^<U+000A>] \n",
      "analyze-step_11 ::= [0-9] | \n",
      "analyze-step_12 ::= [^<U+000A>] analyze-step_12 | [^<U+000A>] \n",
      "identify-step_13 ::= [0-9] | \n",
      "identify-step_14 ::= [^<U+000A>] identify-step_14 | [^<U+000A>] \n",
      "generate-step_15 ::= [0-9] | \n",
      "generate-step_16 ::= [^<U+000A>] generate-step_16 | [^<U+000A>] \n",
      "refine-step_17 ::= [0-9] | \n",
      "refine-step_18 ::= [^<U+000A>] refine-step_18 | [^<U+000A>] \n",
      "ensure-step_19 ::= [0-9] | \n",
      "ensure-step_20 ::= [^<U+000A>] ensure-step_20 | [^<U+000A>] \n",
      "end-of-reasoning_21 ::= [0-9] | \n",
      "end-of-reasoning_22 ::= [^<U+000A>] end-of-reasoning_22 | [^<U+000A>] \n",
      "root ::= root_1 \n",
      "root_1 ::= [^<U+0009>] root_1 | [^<U+0009>] \n",
      "statement ::= statement_3 [:] statement_4 [<U+000A>] \n",
      "statement_3 ::= [^<U+000A>] statement_3 | [^<U+000A>] \n",
      "statement_4 ::= [^<U+000A>] statement_4 | [^<U+000A>] \n",
      "anything ::= anything_6 \n",
      "anything_6 ::= [^<U+0009>] anything_6 | [^<U+0009>] \n",
      "root ::= root_1 [:] root_2 \n",
      "root_1 ::= [^<U+000A>] root_1 | [^<U+000A>] \n",
      "root_2 ::= [^<U+000A>] root_2 | [^<U+000A>] \n",
      "root ::= analyze-step root_3 [<U+000A>] [<U+000A>] [B] [e] [g] [i] [n] [ ] [E] [d] [i] [t] [:] [ ] root_4 \n",
      "analyze-step ::= [S] [t] [e] [p] [ ] analyze-step_8 [0-9] [.] [ ] [A] [n] [a] [l] [y] [z] [e] analyze-step_9 [<U+000A>] \n",
      "step ::= [S] [t] [e] [p] [ ] step_5 [0-9] [.] [ ] step_6 step_7 [<U+000A>] \n",
      "root_3 ::= step root_3 | step \n",
      "root_4 ::= [^<U+000A>] root_4 | [^<U+000A>] \n",
      "step_5 ::= [0-9] | \n",
      "step_6 ::= [A] [n] [a] [l] [y] [z] [e] | [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] | [C] [o] [m] [p] [a] [r] [e] | [S] [k] [i] [p] | [N] [o] [t] [i] [c] [e] | [N] [o] [t] [e] | [T] [h] [e] [r] [e] [ ] [i] [s] | [E] [r] [r] [o] [r] | [I] [ ] [f] [o] [u] [n] [d] | [E] [n] [d] | [T] [h] [e] [r] [e] [ ] [a] [r] [e] \n",
      "step_7 ::= [^<U+000A>] step_7 | [^<U+000A>] \n",
      "analyze-step_8 ::= [0-9] | \n",
      "analyze-step_9 ::= [^<U+000A>] analyze-step_9 | [^<U+000A>] \n",
      "root ::= root_1 \n",
      "root_1 ::= question-one answer [<U+000A>] \n",
      "question-one ::= [1] [.] [)] [ ] question-one_8 [?.!] [<U+000A>] \n",
      "answer ::= [A] [n] [s] [w] [e] [r] [:] [ ] answer_4 [<U+000A>] \n",
      "answer_4 ::= [^<U+000A>] answer_4 | [^<U+000A>] \n",
      "number ::= [1-9] number_6 number_7 \n",
      "number_6 ::= [0-9] | \n",
      "number_7 ::= [0-9] | \n",
      "question-one_8 ::= [^<U+000A>] question-one_8 | [^<U+000A>] \n",
      "root ::= identify-step generate-step brainstorm-step relationships-step if-then-step make-suitable-step \n",
      "identify-step ::= [S] [t] [e] [p] [ ] identify-step_7 [0-9] [.] [ ] [I] [d] [e] [n] [t] [i] [f] [y] [ ] [K] [e] [y] [ ] [T] [o] [p] [i] [c] [s] [:] identify-step_8 [<U+000A>] \n",
      "root ::= step step root_2 [<U+000A>] \n",
      "step ::= [S] [t] [e] [p] [ ] step_5 [0-9] [.] [ ] step_6 step_7 [<U+000A>] \n",
      "root_2 ::= step root_2 | step \n",
      "reasoning-start ::= reasoning-start_4 [.] \n",
      "reasoning-start_4 ::= [^<U+000A><U+0009>] reasoning-start_4 | [^<U+000A><U+0009>] \n",
      "step_5 ::= [0-9] | \n",
      "step_6 ::= [A] [n] [a] [l] [y] [z] [e] | [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] | [C] [o] [m] [p] [a] [r] [e] | [S] [k] [i] [p] | [F] [i] [n] [a] [l] \n",
      "step_7 ::= [^<U+000A>] step_7 | [^<U+000A>] \n",
      "relevant ::= [ ] [r] [e] [l] [e] [v] [a] [n] [t] | [ ] [R] [e] [l] [e] [v] [a] [n] [t] \n",
      "irrelevant ::= [ ] [i] [r] [r] [e] [l] [e] [v] [a] [n] [t] | [ ] [I] [r] [r] [e] [l] [e] [v] [a] [n] [t] \n",
      "root ::= in-depth-analysis [<U+000A>] detailed-understanding [<U+000A>] targeted-comparison [<U+000A>] critical-evaluation \n",
      "in-depth-analysis ::= [#] [#] [#] [ ] [I] [n] [-] [D] [e] [p] [t] [h] [ ] [A] [n] [a] [l] [y] [s] [i] [s] [ ] [o] [f] [ ] [t] [h] [e] [ ] [T] [e] [x] [t] [:] [<U+000A>] content-and-depth type-of-information \n",
      "detailed-understanding ::= [#] [#] [#] [ ] [D] [e] [t] [a] [i] [l] [e] [d] [ ] [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] [i] [n] [g] [ ] [o] [f] [ ] [t] [h] [e] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [:] [<U+000A>] core-requirement depth-of-detail \n",
      "targeted-comparison ::= [#] [#] [#] [ ] [T] [a] [r] [g] [e] [t] [e] [d] [ ] [C] [o] [m] [p] [a] [r] [i] [s] [o] [n] [ ] [o] [f] [ ] [t] [h] [e] [ ] [Q] [u] [e] [s] [t] [i] [o] [n] [ ] [w] [i] [t] [h] [ ] [t] [h] [e] [ ] [T] [e] [x] [t] [:] [<U+000A>] content-match depth-match \n",
      "critical-evaluation ::= [#] [#] [#] [ ] [C] [r] [i] [t] [i] [c] [a] [l] [ ] [E] [v] [a] [l] [u] [a] [t] [i] [o] [n] [ ] [a] [n] [d] [ ] [F] [i] [n] [a] [l] [ ] [J] [u] [d] [g] [m] [e] [n] [t] [:] [<U+000A>] judgment \n",
      "content-and-depth ::= [#] [#] [#] [#] [ ] [C] [o] [n] [t] [e] [n] [t] [ ] [a] [n] [d] [ ] [D] [e] [p] [t] [h] [:] [ ] text-description [<U+000A>] \n",
      "type-of-information ::= [#] [#] [#] [#] [ ] [T] [y] [p] [e] [ ] [o] [f] [ ] [I] [n] [f] [o] [r] [m] [a] [t] [i] [o] [n] [:] [ ] information-description [<U+000A>] \n",
      "text-description ::= text-description_19 \n",
      "information-description ::= information-description_20 \n",
      "core-requirement ::= [#] [#] [#] [#] [ ] [C] [o] [r] [e] [ ] [R] [e] [q] [u] [i] [r] [e] [m] [e] [n] [t] [:] [ ] requirement-description [<U+000A>] \n",
      "depth-of-detail ::= [#] [#] [#] [#] [ ] [D] [e] [p] [t] [h] [ ] [o] [f] [ ] [D] [e] [t] [a] [i] [l] [:] [ ] detail-description [<U+000A>] \n",
      "requirement-description ::= requirement-description_21 \n",
      "detail-description ::= detail-description_22 \n",
      "content-match ::= [#] [#] [#] [#] [ ] [C] [o] [n] [t] [e] [n] [t] [ ] [M] [a] [t] [c] [h] [:] [ ] match-description [<U+000A>] \n",
      "depth-match ::= [#] [#] [#] [#] [ ] [D] [e] [p] [t] [h] [ ] [M] [a] [t] [c] [h] [:] [ ] depth-match-description [<U+000A>] \n",
      "match-description ::= match-description_23 \n",
      "depth-match-description ::= depth-match-description_24 \n",
      "judgment ::= judgment_18 \n",
      "judgment_18 ::= [^<U+000A>] judgment_18 | [^<U+000A>] \n",
      "text-description_19 ::= [^<U+000A>] text-description_19 | [^<U+000A>] \n",
      "information-description_20 ::= [^<U+000A>] information-description_20 | [^<U+000A>] \n",
      "requirement-description_21 ::= [^<U+000A>] requirement-description_21 | [^<U+000A>] \n",
      "detail-description_22 ::= [^<U+000A>] detail-description_22 | [^<U+000A>] \n",
      "match-description_23 ::= [^<U+000A>] match-description_23 | [^<U+000A>] \n",
      "depth-match-description_24 ::= [^<U+000A>] depth-match-description_24 | [^<U+000A>] \n",
      "relevance ::= [R] [e] [l] [e] [v] [a] [n] [t] [.] | [I] [r] [r] [e] [l] [e] [v] [a] [n] [t] [.] \n",
      "root ::= root_1 root_4 root_6 root_8 \n",
      "root_1 ::= question-one answer [<U+000A>] \n",
      "question-one ::= [1] [.] [)] [ ] question-one_14 [?.!] [<U+000A>] [<U+000A>] \n",
      "answer ::= [A] [n] [s] [w] [e] [r] [:] [ ] answer_10 [<U+000A>] \n",
      "root_4 ::= question-two answer [<U+000A>] \n",
      "question-two ::= [2] [.] [)] [ ] question-two_15 [?.!] [<U+000A>] [<U+000A>] \n",
      "root_6 ::= question-three answer [<U+000A>] \n",
      "question-three ::= [3] [.] [)] [ ] question-three_16 [?.!] [<U+000A>] [<U+000A>] \n",
      "root_8 ::= question-four answer \n",
      "question-four ::= [4] [.] [)] [ ] question-four_17 [?.!] [<U+000A>] [<U+000A>] \n",
      "answer_10 ::= [^<U+000A>] answer_10 | [^<U+000A>] \n",
      "number ::= [1-9] number_12 number_13 \n",
      "number_12 ::= [0-9] | \n",
      "number_13 ::= [0-9] | \n",
      "question-one_14 ::= [^<U+000A>] question-one_14 | [^<U+000A>] \n",
      "question-two_15 ::= [^<U+000A>] question-two_15 | [^<U+000A>] \n",
      "question-three_16 ::= [^<U+000A>] question-three_16 | [^<U+000A>] \n",
      "question-four_17 ::= [^<U+000A>] question-four_17 | [^<U+000A>] \n",
      "root ::= reasoning \n",
      "reasoning ::= reasoning_2 [\"] [\"] [\"] \n",
      "reasoning_2 ::= [^<U+000A>] reasoning_2 | [^<U+000A>] \n",
      "root ::= reasoning \n",
      "reasoning ::= reasoning_2 [.] \n",
      "reasoning_2 ::= [^<U+000A>] reasoning_2 | [^<U+000A>] \n",
      "root ::= reasoning-start \n",
      "reasoning-start ::= reasoning-start_2 [.] \n",
      "reasoning-start_2 ::= [^<U+000A><U+0009>] reasoning-start_2 | [^<U+000A><U+0009>] \n",
      "root ::= consider-question-step consider-character-step constrain-step setting-step create-step second-message-step [<U+000A>] \n",
      "consider-question-step ::= [S] [t] [e] [p] [ ] consider-question-step_7 [0-9] [.] [ ] [F] [o] [c] [u] [s] [ ] [o] [n] [ ] [t] [h] [e] [ ] [q] [u] [e] [s] [t] [i] [o] [n] [ ] [a] [n] [d] [ ] [a] [n] [s] [w] [e] [r] [:] [ ] [T] [h] [e] [ ] [q] [u] [e] [s] [t] [i] [o] [n] consider-question-step_8 [<U+000A>] \n",
      "consider-character-step ::= [S] [t] [e] [p] [ ] consider-character-step_9 [0-9] [.] [ ] [C] [h] [a] [r] [a] [c] [t] [e] [r] [ ] [C] [o] [n] [s] [i] [d] [e] [r] [a] [t] [i] [o] [n] [:] [ ] [T] [h] [e] [ ] [p] [r] [i] [m] [a] [r] [y] [ ] [c] [h] [a] [r] [a] [c] [t] [e] [r] [ ] [i] [s] consider-character-step_10 [<U+000A>] \n",
      "constrain-step ::= [S] [t] [e] [p] [ ] constrain-step_11 [0-9] [.] [ ] [C] [o] [n] [s] [t] [r] [a] [i] [n] [ ] [t] [h] [e] [ ] [S] [c] [e] [n] [a] [r] [i] [o] [:] [ ] [T] [h] [e] [ ] [i] [n] [t] [e] [r] [a] [c] [t] [i] [o] [n] [ ] [i] [s] [ ] [l] [i] [m] [i] [t] [e] [d] [ ] [t] [o] [ ] [a] [ ] [s] [i] [n] [g] [l] [e] [ ] [q] [u] [e] [s] [t] [i] [o] [n] [ ] [f] [r] [o] [m] [ ] [t] [h] [e] [ ] [s] [e] [c] [o] [n] [d] [a] [r] [y] [ ] [c] [h] [a] [r] [a] [c] [t] [e] [r] [ ] [a] [n] [d] [ ] [a] [ ] [s] [i] [n] [g] [l] [e] [,] [ ] [f] [o] [c] [u] [s] [e] [d] [ ] [r] [e] [p] [l] [y] [ ] [f] [r] [o] [m] constrain-step_12 [<U+000A>] \n",
      "setting-step ::= [S] [t] [e] [p] [ ] setting-step_13 [0-9] [.] [ ] [S] [e] [t] [t] [i] [n] [g] [:] [ ] [G] [i] [v] [e] [n] [ ] [t] [h] [e] [ ] [s] [u] [b] [j] [e] [c] [t] [ ] [o] [f] [ ] [t] [h] [e] [ ] [q] [u] [e] [s] [t] [i] [o] [n] [,] [ ] [a] [n] [d] [ ] [t] [h] [e] [ ] [c] [h] [a] [r] [a] [c] [t] [e] [r] [ ] [c] [a] [r] [d] [,] [ ] [t] [h] [e] [ ] [s] [e] [t] [t] [i] [n] [g] [ ] [w] [i] [l] [l] [ ] [b] [e] setting-step_14 [<U+000A>] \n",
      "create-step ::= [S] [t] [e] [p] [ ] create-step_15 [0-9] [.] [ ] [I] [n] [t] [e] [r] [a] [c] [t] [i] [o] [n] [:] [ ] [G] [i] [v] [e] [n] [ ] [t] [h] [e] [s] [e] [ ] [c] [o] [n] [s] [t] [r] [a] [i] [n] [t] [s] [,] [ ] [t] [h] [e] [ ] [f] [i] [r] [s] [t] [ ] [m] [e] [s] [s] [a] [g] [e] [ ] [(] [d] [e] [l] [i] [v] [e] [r] [e] [d] [ ] [b] [y] [ ] [t] [h] [e] [ ] [s] [e] [c] [o] [n] [d] [a] [r] [y] [ ] [c] [h] [a] [r] [a] [c] [t] [e] [r] [)] [ ] [m] [i] [g] [h] [t] create-step_16 [<U+000A>] \n",
      "second-message-step ::= [S] [t] [e] [p] [ ] second-message-step_17 [0-9] [.] [ ] [I] [n] [ ] [t] [h] [e] [ ] [s] [e] [c] [o] [n] [d] [ ] [m] [e] [s] [s] [a] [g] [e] [,] second-message-step_18 [<U+000A>] \n",
      "consider-question-step_7 ::= [0-9] | \n",
      "consider-question-step_8 ::= [^<U+000A>] consider-question-step_8 | [^<U+000A>] \n",
      "consider-character-step_9 ::= [0-9] | \n",
      "consider-character-step_10 ::= [^<U+000A>] consider-character-step_10 | [^<U+000A>] \n",
      "constrain-step_11 ::= [0-9] | \n",
      "constrain-step_12 ::= [^<U+000A>] constrain-step_12 | [^<U+000A>] \n",
      "setting-step_13 ::= [0-9] | \n",
      "setting-step_14 ::= [^<U+000A>] setting-step_14 | [^<U+000A>] \n",
      "create-step_15 ::= [0-9] | \n",
      "create-step_16 ::= [^<U+000A>] create-step_16 | [^<U+000A>] \n",
      "second-message-step_17 ::= [0-9] | \n",
      "second-message-step_18 ::= [^<U+000A>] second-message-step_18 | [^<U+000A>] \n",
      "root ::= consider-question-step consider-character-step constrain-step setting-step create-step [<U+000A>] \n",
      "consider-question-step ::= [S] [t] [e] [p] [ ] consider-question-step_6 [0-9] [.] [ ] [F] [o] [c] [u] [s] [ ] [o] [n] [ ] [t] [h] [e] [ ] [q] [u] [e] [s] [t] [i] [o] [n] [ ] [a] [n] [d] [ ] [a] [n] [s] [w] [e] [r] [:] consider-question-step_7 [<U+000A>] \n",
      "consider-character-step ::= [S] [t] [e] [p] [ ] consider-character-step_8 [0-9] [.] [ ] [C] [h] [a] [r] [a] [c] [t] [e] [r] [ ] [C] [o] [n] [s] [i] [d] [e] [r] [a] [t] [i] [o] [n] [:] consider-character-step_9 [<U+000A>] \n",
      "constrain-step ::= [S] [t] [e] [p] [ ] constrain-step_10 [0-9] [.] [ ] [C] [o] [n] [s] [t] [r] [a] [i] [n] [ ] [t] [h] [e] [ ] [S] [c] [e] [n] [a] [r] [i] [o] [:] [ ] [T] [h] [e] [ ] [i] [n] [t] [e] [r] [a] [c] [t] [i] [o] [n] constrain-step_11 [<U+000A>] \n",
      "setting-step ::= [S] [t] [e] [p] [ ] setting-step_12 [0-9] [.] [ ] [S] [e] [t] [t] [i] [n] [g] [:] [ ] [G] [i] [v] [e] [n] [ ] [t] [h] [e] [ ] [s] [u] [b] [j] [e] [c] [t] [ ] [o] [f] [ ] [t] [h] [e] [ ] [q] [u] [e] [s] [t] [i] [o] [n] [,] [ ] [a] [n] [d] [ ] [t] [h] [e] [ ] [c] [h] [a] [r] [a] [c] [t] [e] [r] [ ] [c] [a] [r] [d] [,] [ ] [t] [h] [e] [ ] [s] [e] [t] [t] [i] [n] [g] [ ] [w] [i] [l] [l] [ ] [b] [e] setting-step_13 [<U+000A>] \n",
      "create-step ::= [S] [t] [e] [p] [ ] create-step_14 [0-9] [.] [ ] [I] [n] [t] [e] [r] [a] [c] [t] [i] [o] [n] [:] [ ] [G] [i] [v] [e] [n] [ ] [t] [h] [e] [s] [e] [ ] [c] [o] [n] [s] [t] [r] [a] [i] [n] [t] [s] [,] [ ] [t] [h] [e] [ ] [f] [i] [r] [s] [t] [ ] [m] [e] [s] [s] [a] [g] [e] [ ] [m] [i] [g] [h] [t] create-step_15 [<U+000A>] \n",
      "consider-question-step_6 ::= [0-9] | \n",
      "consider-question-step_7 ::= [^<U+000A>] consider-question-step_7 | [^<U+000A>] \n",
      "consider-character-step_8 ::= [0-9] | \n",
      "consider-character-step_9 ::= [^<U+000A>] consider-character-step_9 | [^<U+000A>] \n",
      "constrain-step_10 ::= [0-9] | \n",
      "constrain-step_11 ::= [^<U+000A>] constrain-step_11 | [^<U+000A>] \n",
      "setting-step_12 ::= [0-9] | \n",
      "setting-step_13 ::= [^<U+000A>] setting-step_13 | [^<U+000A>] \n",
      "create-step_14 ::= [0-9] | \n",
      "create-step_15 ::= [^<U+000A>] create-step_15 | [^<U+000A>] \n",
      "root ::= statement [<U+000A>] [<U+000A>] response [<U+000A>] \n",
      "statement ::= statement_3 [:] statement_4 \n",
      "response ::= response_5 [:] response_6 \n",
      "statement_3 ::= [^<U+000A>] statement_3 | [^<U+000A>] \n",
      "statement_4 ::= [^<U+000A>] statement_4 | [^<U+000A>] \n",
      "response_5 ::= [^<U+000A>] response_5 | [^<U+000A>] \n",
      "response_6 ::= [^<U+000A>] response_6 | [^<U+000A>] \n",
      "character-name ::= word | word word | word word word | word word word word | word word word word word | word word word word word word \n",
      "word ::= word_11 \n",
      "character-name_9 ::= [-] word \n",
      "character-name_10 ::= character-name_9 character-name_10 | \n",
      "word_11 ::= [A-Za-z] word_11 | [A-Za-z] \n",
      "dialogue-line ::= dialogue-line_13 \n",
      "dialogue-line_13 ::= [^<U+000A>] dialogue-line_13 | [^<U+000A>] \n",
      "root ::= root_2 [<U+000A>] \n",
      "step ::= [S] [t] [e] [p] [ ] step_3 [0-9] [.] [ ] step_4 step_5 [<U+000A>] \n",
      "root_2 ::= step root_2 | step \n",
      "step_3 ::= [0-9] | \n",
      "step_4 ::= [R] [e] [a] [l] [i] [z] [e] | [R] [e] [c] [o] [g] [n] [i] [z] [e] | [C] [o] [n] [c] [l] [u] [d] [e] | [R] [e] [c] [a] [l] [l] | [R] [e] [m] [e] [m] [b] [e] [r] | [F] [o] [r] [m] [u] [l] [a] [t] [e] | [D] [e] [c] [o] [m] [p] [o] [s] [e] | [B] [r] [e] [a] [k] [ ] [d] [o] [w] [n] | [B] [r] [e] [a] [k] | [T] [h] [e] [r] [e] [f] [o] [r] [e] [,] [ ] [t] [h] [e] [ ] [a] [n] [s] [w] [e] [r] [ ] [i] [s] | [T] [h] [e] [ ] [a] [n] [s] [w] [e] [r] [ ] [i] [s] | [R] [e] [a] [l] [i] [s] [e] | [C] [a] [l] [c] [u] [l] [a] [t] [e] | [U] [n] [d] [e] [r] [s] [t] [a] [n] [d] | [N] [o] [t] [e] | [T] [h] [e] [ ] [p] [l] [a] [n] [ ] [w] [i] [l] [l] \n",
      "step_5 ::= [^<U+000A>] step_5 | [^<U+000A>] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "print_grammar: error printing grammar: malformed rule, does not end with LLAMA_GRETYPE_END: 2\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n",
      "from_string grammar:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is in no way best practices, but all my prompts being searchable and separate files is a good way to make my life easier.\n",
    "import pkgutil\n",
    "import importlib\n",
    "import generation_functions  # This is the package directory\n",
    "import sys\n",
    "\n",
    "sys.path.append('./generation_functions')\n",
    "\n",
    "# First, import all modules so they can be reloaded\n",
    "for _, module_name, _ in pkgutil.iter_modules(generation_functions.__path__, generation_functions.__name__ + '.'):\n",
    "    importlib.import_module(module_name)\n",
    "\n",
    "# Now, reload each module and import all callable attributes\n",
    "for _, module_name, _ in pkgutil.iter_modules(generation_functions.__path__, generation_functions.__name__ + '.'):\n",
    "    # Reload the module\n",
    "    module = importlib.reload(sys.modules[module_name])\n",
    "    # Iterate through each attribute in the reloaded module\n",
    "    for attribute_name in dir(module):\n",
    "        # Retrieve the attribute\n",
    "        attribute = getattr(module, attribute_name)\n",
    "        if callable(attribute):\n",
    "            # If it's callable, it's a function or class, so you set it in the globals dictionary\n",
    "            globals()[attribute_name] = attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which paragraphs are worthy of making questions from\n",
    "judged_worthy_for_questions = []\n",
    "for idx, p in tqdm(enumerate(paragraphs_processed)): # for each paragraph, try determining if it is suitable for questions or not, at most three times each\n",
    "    judgement = judge_paragraph(p,logic_llm)\n",
    "    judged_worthy_for_questions.append(judgement)\n",
    "    try:\n",
    "        if judgement[0] is not None:\n",
    "            print(f\"DEBUG model decided that index {idx} was suitable\")\n",
    "        elif judgement[0] is None:\n",
    "            print(f\"DEBUG model decided that index {idx} was not suitable\")\n",
    "    except:\n",
    "        print(f\"DEBUG max retries exceeded for index {idx}\")\n",
    "    \n",
    "        \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing code generated by GPT-4. May be suboptimal/ugly.\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def filter_and_graph(tuples):\n",
    "    # Count the occurrences of None and non-None for each source text\n",
    "    source_counts = Counter()\n",
    "    for paragraph, source in tuples:\n",
    "        if paragraph is None:\n",
    "            source_counts[source] = source_counts.get(source, [0, 0])\n",
    "            source_counts[source][0] += 1\n",
    "        else:\n",
    "            source_counts[source] = source_counts.get(source, [0, 0])\n",
    "            source_counts[source][1] += 1\n",
    "\n",
    "    # Prepare data for the graph\n",
    "    labels = list(source_counts.keys())\n",
    "    none_counts = [source_counts[source][0] for source in labels]\n",
    "    non_none_counts = [source_counts[source][1] for source in labels]\n",
    "\n",
    "    # Plotting the graph\n",
    "    x = range(len(labels))\n",
    "    plt.bar(x, none_counts, width=0.4, label='Not suitable', align='center')\n",
    "    plt.bar(x, non_none_counts, width=0.4, label='Valid Paragraphs', align='edge')\n",
    "    plt.xlabel('Source Text')\n",
    "    plt.ylabel('Number of Paragraphs')\n",
    "    plt.title('Paragraphs Suitable for Questions by Source Text')\n",
    "    plt.xticks(x, labels, rotation='vertical')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Filter out tuples with None and return the new list\n",
    "    filtered_list = [t for t in tuples if t[0] is not None]\n",
    "    return filtered_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_worthy_for_questions = filter_and_graph(judged_worthy_for_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Answer generation code, begin.\n",
    "# structure: define a series of helpers, then define the control flow, exception handling, retries etc. in a for loop that iterates over the processed sequences of paragraphs at the end in another cell\n",
    "\n",
    "# Since some paragraphs can be much shorter \n",
    "# First off, question generation.\n",
    "\n",
    "# Each local LLM function essentially has 3 phases: prompt, regex to extract response, and reaction to that response.\n",
    "# However I'm not going to build an abstraction for that because I need fine control.\n",
    "\n",
    "# If any function fails to make things, it won't throw, it'll just return None.\n",
    "\n",
    "# Strengths of open source AI: hella cheap, very customizable, you can call it as much as you want\n",
    "# Downside: you need very good regexes to catch its outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_worthy_for_questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def write_output_to_file(output, directory, uuid):\n",
    "    # Ensure directory exists\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Define the file path using the directory and UUID\n",
    "    file_path = os.path.join(directory, f\"{uuid}.txt\")\n",
    "    \n",
    "    # Write the output to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(output)\n",
    "    \n",
    "    print(f\"Output written to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control flow helpers\n",
    "\n",
    "# Change this value to change how many times the checks must pass consecutively for a thing to be accepted\n",
    "\n",
    "import logging\n",
    "from math import ceil\n",
    "import uuid\n",
    "\n",
    "def make_id():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "\n",
    "# Setup logging\n",
    "# Except I actually don't use this because I switched to print() because jupyter (only to find out at the end of this )\n",
    "logging.basicConfig(filename='data_generation.log', \n",
    "                    filemode='a', \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "def tokenize_and_check_length(text):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens) > 500, tokens\n",
    "\n",
    "def vet_answer_accuracy_loop(qa_tuple,total_retries,run_id):\n",
    "    try:\n",
    "        qtuple = qa_tuple\n",
    "        print(f\"\\n\\nStarting ACCURACY loop for question: {qtuple[0]}, context: {qtuple[2]}\")\n",
    "        passed_checks = 0\n",
    "        times_checked = 0\n",
    "        dissenting_reasoning = \"\"\n",
    "        while times_checked < DOUBLE_CHECK_COUNTER:\n",
    "            print(f\"\\n\\nACCURACY CALL CHECK ANSWER: {qtuple[0]}, context: {qtuple[2]}, retries: {total_retries}, dissenting reasoning: {dissenting_reasoning}\")\n",
    "            judgement, answer_accuracy_output = check_answer(qtuple, logic_llm)\n",
    "            write_output_to_file(answer_accuracy_output, \"./check_answer_accuracy_generations\", run_id)\n",
    "            if not judgement[0]:  # if not accurate\n",
    "                dissenting_reasoning = judgement[1]\n",
    "            else:\n",
    "                passed_checks += 1\n",
    "            times_checked+=1\n",
    "            if passed_checks >= ceil(DOUBLE_CHECK_COUNTER/2):\n",
    "                break\n",
    "            failed_checks = times_checked - passed_checks\n",
    "            if failed_checks >= ceil(DOUBLE_CHECK_COUNTER/2):\n",
    "                break\n",
    "        \n",
    "        if passed_checks >= ceil(DOUBLE_CHECK_COUNTER/2):  # if question checks passed\n",
    "            print(f\"\\n\\ANSWER ACCURACY CHECKS PASSED retries: {total_retries}\")\n",
    "            return qtuple\n",
    "        else:\n",
    "            # Generate new question and restart the loop\n",
    "            print(f\"\\n\\nACCURACY CHECKS FAILED - SENDING BACK TO QUESTION LOOP retries: {total_retries}\")\n",
    "            total_retries += 1\n",
    "            qtuple, generate_new_q_output = generate_new_question(qtuple, logic_llm)\n",
    "            write_output_to_file(generate_new_q_output, \"./regenerate_question_generations\", run_id)\n",
    "            vet_question_loop(qtuple,total_retries,run_id=run_id.split(\"--subquestion--\")[0]) # going to get one hell of a call stack by the end of this, but it should be fine\n",
    "    except Exception as e:\n",
    "        print(\"!!ERROR!!\")\n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "    return (None, None, None, qtuple[3])\n",
    "\n",
    "def vet_answer_relevance_loop(qa_tuple,total_retries,run_id):\n",
    "    try:\n",
    "        qtuple = qa_tuple\n",
    "        print(f\"\\n\\nStarting RELEVANCE loop for question: {qtuple[0]}, context: {qtuple[2]}\")\n",
    "        passed_checks = 0\n",
    "        times_checked = 0\n",
    "        dissenting_reasoning = \"\"\n",
    "        while times_checked < DOUBLE_CHECK_COUNTER:\n",
    "            print(f\"\\n\\nRELEVANCE CALL CHECK ANSWER: {qtuple[0]}, context: {qtuple[2]}, retries: {total_retries}, dissenting reasoning: {dissenting_reasoning}\")\n",
    "            judgement, answer_relevancy_output = check_answer_relevancy_with_text(qtuple, logic_llm)\n",
    "            write_output_to_file(answer_relevancy_output, \"./check_answer_relevancy_generations\", run_id)\n",
    "            if not judgement[0]:  # if not relevant\n",
    "                dissenting_reasoning = judgement[1]\n",
    "            else:\n",
    "                passed_checks += 1\n",
    "            times_checked += 1\n",
    "            if passed_checks >= ceil(DOUBLE_CHECK_COUNTER/2):\n",
    "                break\n",
    "            failed_checks = times_checked - passed_checks\n",
    "            if failed_checks >= ceil(DOUBLE_CHECK_COUNTER/2):\n",
    "                break\n",
    "        \n",
    "        if passed_checks >= ceil(DOUBLE_CHECK_COUNTER/2):\n",
    "            print(f\"\\n\\nRELEVANCE CHECKS PASSED\")\n",
    "            return vet_answer_accuracy_loop(qtuple,total_retries,run_id)\n",
    "        else:\n",
    "            print(f\"\\n\\nRELEVANCE CHECKS FAILED - SENDING BACK TO QUESTION LOOP\")\n",
    "            total_retries += 1\n",
    "            qtuple, generate_new_q_output = generate_new_question(qtuple, logic_llm)\n",
    "            write_output_to_file(generate_new_q_output, \"./regenerate_question_generations\", run_id)\n",
    "            return vet_question_loop(qtuple,total_retries,run_id=run_id.split(\"--subquestion--\")[0])\n",
    "    except Exception as e:\n",
    "        print(\"!!ERROR!!\")\n",
    "        print(e)\n",
    "        pass\n",
    "    \n",
    "    return (None, None, None, qtuple[3])\n",
    "\n",
    "def vet_question_loop(qa_tuple, question_group_id=None, total_retries=0):\n",
    "    try:\n",
    "        qtuple = qa_tuple\n",
    "        print(f\"\\n\\nStarting QUESTION loop for question: {qtuple[0]}, context: {qtuple[2]}\")\n",
    "        while total_retries <= 4:\n",
    "            run_id = question_group_id + \"--subquestion--\" + make_id()\n",
    "            passed_checks = 0\n",
    "            times_checked = 0\n",
    "            dissenting_reasoning = \"\"\n",
    "            while times_checked < DOUBLE_CHECK_COUNTER:\n",
    "                print(f\"\\n\\nQUESTION CALL CHECK ANSWER: {qtuple[0]}, context: {qtuple[2]}, retries: {total_retries}, dissenting reasoning: {dissenting_reasoning}\")\n",
    "                judgement, check_q_output = check_question(qtuple, logic_llm)\n",
    "                write_output_to_file(check_q_output, \"./check_question_generations\", run_id)\n",
    "                if not judgement[0]:  # if not relevant\n",
    "                    dissenting_reasoning = judgement[1]\n",
    "                else:\n",
    "                    passed_checks += 1\n",
    "                times_checked += 1\n",
    "                if passed_checks >= ceil(DOUBLE_CHECK_COUNTER/2):\n",
    "                    break\n",
    "                failed_checks = times_checked - passed_checks\n",
    "                if failed_checks >= ceil(DOUBLE_CHECK_COUNTER/2):\n",
    "                    break\n",
    "            \n",
    "            if passed_checks >= ceil(DOUBLE_CHECK_COUNTER/2):  # if all question checks passed\n",
    "                print(f\"\\n\\nQUESTION CHECKS PASSED retries: {total_retries}\")\n",
    "                return vet_answer_relevance_loop(qtuple,total_retries,run_id)\n",
    "            else:\n",
    "                # Generate new question and restart the loop\n",
    "                print(f\"\\n\\nQUESTION CHECKS FAILED - GENERATING NEW QUESTION retries: {total_retries}\")\n",
    "                total_retries += 1\n",
    "                if (total_retries <= 4): # don't regen question if we're already at max regens\n",
    "                    qtuple, generate_new_q_output = generate_new_question(qtuple, logic_llm) \n",
    "                    write_output_to_file(generate_new_q_output, \"./regenerate_question_generations\", run_id)\n",
    "                    print(\"New question: \", qtuple)\n",
    "                # no calling of vet_question_loop, since we're already in a while loop\n",
    "    except Exception as e:\n",
    "        print(\"!!ERROR!!\")\n",
    "        print(e)\n",
    "    \n",
    "    return (None, None, None, qtuple[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control flow\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "# Directory for QA tuples\n",
    "qa_tuples_dir = './qatuples_raw'\n",
    "if not os.path.exists(qa_tuples_dir):\n",
    "    os.makedirs(qa_tuples_dir)\n",
    "\n",
    "\n",
    "# Generate questions CoT-style\n",
    "vetted_qa_tuples = [] # tuple list of qa tuples that have been judged good\n",
    "for idx, para in enumerate(tqdm(filtered_worthy_for_questions)):\n",
    "    try:\n",
    "        existing_files = glob.glob(os.path.join(qa_tuples_dir, f'para_{idx}_*.json')) # check if qs already exist\n",
    "    \n",
    "        if len(existing_files) > 0:  # If files exist, skip this paragraph entirely\n",
    "            print(f\"Skipping para_{idx} as files already exist.\")\n",
    "            continue\n",
    "\n",
    "        question_group_id = make_id()\n",
    "        print(f\"\\n\\n\\nOUTER LOOP CALL GENERATE QPLAN para: {para}, \\n\\n idx: {idx}\")\n",
    "        plan, questions_plan_output = generate_questions_plan(para,logic_llm)\n",
    "        write_output_to_file(questions_plan_output, \"./question_plan_generations\", question_group_id)\n",
    "        print(f\"\\n\\n\\nOUTER LOOP CALL GENERATE Q: {para}, \\n\\n idx: {idx} \\n\\n plan: {plan}\")\n",
    "        question_answer_tuples, question_generation_output = generate_questions(para,plan,logic_llm)\n",
    "        write_output_to_file(question_generation_output, \"./question_generation_generations\", question_group_id)\n",
    "        for qnum, question_answer_tuple in enumerate(question_answer_tuples):\n",
    "            print(f\"\\n\\n=======!!=BEGIN VETTING QA TUPLE {idx}_{qnum}=!!=======\\n\\n\")\n",
    "            good_qa_tuple = vet_question_loop(question_answer_tuple,question_group_id=question_group_id)\n",
    "            \n",
    "            # Write resulting question file if the tuple is not None\n",
    "            if good_qa_tuple[0] is not None:\n",
    "                file_path = os.path.join(qa_tuples_dir, f'para_{idx}_q_{qnum}.json')\n",
    "                with open(file_path, 'w') as file:\n",
    "                    json.dump(good_qa_tuple, file, indent=4)\n",
    "            \n",
    "            vetted_qa_tuples.append(good_qa_tuple) # We must filter out all None values at the end; but appending Nones lets us know where things went wrong, and how often.\n",
    "    except Exception as e:\n",
    "        print(f\"Q ERROR: {e}\")\n",
    "        \n",
    "print(\"-------------- QUESTIONS CREATED ------------- STATS SO FAR:\")\n",
    "nones= list(filter(lambda x: x[0] is None, vetted_qa_tuples))\n",
    "print(f\"Nones: {len(nones)}\")\n",
    "print(f\"Non-nones: {len(vetted_qa_tuples) - len(nones)}\")\n",
    "print(f\"Total: {len(vetted_qa_tuples)}\")\n",
    "# filter out all None values\n",
    "vetted_qa_tuples = [qa for qa in vetted_qa_tuples if qa[0] is not None]\n",
    "print(\"---------------- ONTO EXAMPLES GENERATION-------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing code again generated by GPT-4. I believe that this one is bugged.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Counting nones vs non-nones for questions per source text\n",
    "qa_counts = {}\n",
    "for qa in vetted_qa_tuples:\n",
    "    source_text = qa[3] if qa[3] is not None else 'Unknown'\n",
    "    if source_text not in qa_counts:\n",
    "        qa_counts[source_text] = {'None': 0, 'Valid': 0}\n",
    "    \n",
    "    if qa[0] is None:\n",
    "        qa_counts[source_text]['None'] += 1\n",
    "    else:\n",
    "        qa_counts[source_text]['Valid'] += 1\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Data for plotting\n",
    "sources = list(qa_counts.keys())\n",
    "none_counts = [qa_counts[src]['None'] for src in sources]\n",
    "valid_counts = [qa_counts[src]['Valid'] for src in sources]\n",
    "\n",
    "# Creating the bar plot\n",
    "ax.bar(sources, valid_counts, label='Valid QA Tuples')\n",
    "ax.bar(sources, none_counts, bottom=valid_counts, label='None QA Tuples')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Source Text')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Number of None vs Valid QA Tuples per Source Text')\n",
    "ax.legend()\n",
    "\n",
    "# Rotate labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for and fix the common mistake: mentioning \"the text\".\n",
    "old_tuples = vetted_qa_tuples.copy()\n",
    "for idx, tup in enumerate(vetted_qa_tuples):\n",
    "    try:\n",
    "        revision_id = make_id()\n",
    "        revision, revision_output = check_qatuple_context(tup,logic_llm)\n",
    "        write_output_to_file(revision_output, \"./question_context_revision_generations\", revision_id) # incidentally, identifying the problem and fixing it in the same step (without another planning step) works a lot better than identifying it and then trying to fix it in the next step.\n",
    "        if (isinstance(revision[0],str)): # if the thing was reworded\n",
    "            vetted_qa_tuples[idx] = revision\n",
    "        elif (not revision[0]):\n",
    "            vetted_qa_tuples[idx] = None # prepare item for deletion later; right now we just store it as None because indexes\n",
    "        # else, if it passed, we just leave it be.\n",
    "    except Exception as e:\n",
    "        print (\"!!! ERROR!\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If vetted_qa_tuples is not defined (user of notebook skips previous steps because they generated questions in an earlier run) then this cell provides the functionality to read qatuples back in from files.\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def read_json_files(directory):\n",
    "    # List to hold all tuples\n",
    "    all_tuples = []\n",
    "    \n",
    "    # Get all the json files from the given directory\n",
    "    json_files = [f for f in Path(directory).iterdir() if f.suffix == '.json']\n",
    "    \n",
    "    # Function to extract numbers from filename for sorting\n",
    "    def extract_numbers(filename):\n",
    "        numbers = re.findall(r'\\d+', filename.stem)\n",
    "        return [int(num) for num in numbers] if numbers else [0]\n",
    "\n",
    "    # Sort files based on numbers extracted from filenames\n",
    "    sorted_files = sorted(json_files, key=extract_numbers)\n",
    "\n",
    "    # Read each file and extract tuples\n",
    "    for file in sorted_files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "            # Extract numbers from filename\n",
    "            numbers = extract_numbers(file)\n",
    "            \n",
    "            # Use the first number as para_num, default to 0 if not present\n",
    "            para_num = numbers[0] if numbers else 0\n",
    "            \n",
    "            # Ensure we have the list to hold tuples for this para_num\n",
    "            if para_num >= len(all_tuples):\n",
    "                all_tuples.extend([[] for _ in range(para_num - len(all_tuples) + 1)])\n",
    "            \n",
    "            # Extract the tuple and add to the corresponding sublist\n",
    "            q_a_tuple = (data[0], data[1], data[2], data[3])\n",
    "            all_tuples[para_num].append(q_a_tuple)\n",
    "            \n",
    "    return all_tuples\n",
    "\n",
    "# The directory path relative to the notebook\n",
    "directory_path = './qatuples_revised'\n",
    "\n",
    "# read vetted qa tuples from files, if not defined\n",
    "try:\n",
    "    vetted_qa_tuples\n",
    "except:\n",
    "    # Call the function to read JSON files if vetted_qa_tuples not defined\n",
    "    vetted_qa_tuples = read_json_files(directory_path)\n",
    "    vetted_qa_tuples = [item for sublist in vetted_qa_tuples if sublist for item in sublist]\n",
    "    vetted_qa_tuples[:3]  # Display the first 3 sublists for brevity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print stats related to revised qatuples, and filter out nones (questions that were unanswerable due to lack of context).\n",
    "import json\n",
    "import os\n",
    "print(\"-------------- QUESTIONS REVISED ------------- STATS SO FAR:\")\n",
    "nones= list(filter(lambda x: x is None, vetted_qa_tuples))\n",
    "print(f\"Nones: {len(nones)}\")\n",
    "print(f\"Non-nones: {len(vetted_qa_tuples) - len(nones)}\")\n",
    "print(f\"Total: {len(vetted_qa_tuples)}\")\n",
    "# filter out all None values\n",
    "vetted_qa_tuples = [qa for qa in vetted_qa_tuples if qa is not None]\n",
    "writepath = \"./qatuples_revised\"\n",
    "if not os.path.exists(writepath):\n",
    "    os.makedirs(writepath)\n",
    "for idx, qatup in enumerate(vetted_qa_tuples):\n",
    "    file_path = os.path.join(writepath, f'conv_{idx}.json')\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(qatup,file,indent=4)\n",
    "print(\"---------------- ONTO EXAMPLES GENERATION-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group tuples for multiturn example generation (by chunk of source text) and then run that helper (so that we can make multiturn conversations from questions based on the same paragraphs)\n",
    "def group_by_text(tuples_list):\n",
    "    # Dictionary to hold the groups with text as the key\n",
    "    groups = {}\n",
    "    \n",
    "    # Iterate over each tuple in the list\n",
    "    for question, answer, text, textname in tuples_list:\n",
    "        # If the text is not yet a key in the dictionary, add it with an empty list\n",
    "        if text not in groups:\n",
    "            groups[text] = []\n",
    "        \n",
    "        # Append the current tuple to the appropriate list\n",
    "        groups[text].append((question, answer, text,textname))\n",
    "        \n",
    "    # Return the values of the dictionary, which are the lists of tuples grouped by text; also remove duplicates\n",
    "    return [identify_duplicates(group) for group in list(groups.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_tuples_by_paragraph = group_by_text(vetted_qa_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "# multiturn helpers\n",
    "# These will probably be used for multiturn rapid-fire answering.\n",
    "\n",
    "# Idea: use multiple short answers to train the task of answering multiple questions in one response. Two-three short answers per response should be enough.\n",
    "def make_multiturn_character(qa_tuples,conv_id):\n",
    "    plan, instructions, card_plan_output = create_character_card_plan_many_tuples(qa_tuples,logic_llm) # I will reuse the many tuples function for short question-answers, there's a lot of prompting in here already\n",
    "    write_output_to_file(card_plan_output, \"./multiturn_card_plan_generations\", conv_id)\n",
    "    char, char_output = create_character_card_many_tuples(qa_tuples,plan,instructions,logic_llm) # creates a character card\n",
    "    write_output_to_file(char_output, \"./multiturn_card_generations\", conv_id)    \n",
    "    return char, instructions\n",
    "\n",
    "def make_multiturn_scenario(qa_tuples,character,conv_id):\n",
    "    plan, scenario_plan_output = create_scenario_plan_many_tuples(qa_tuples,character,logic_llm)\n",
    "    write_output_to_file(scenario_plan_output, \"./multiturn_scenario_plan_generations\", conv_id)\n",
    "    scenario, scenario_output = create_scenario_many_tuples(qa_tuples,character,plan,logic_llm) # creates a scenario based on a character card and question/answer tuple\n",
    "    write_output_to_file(scenario_output, \"./multiturn_scenario_generations\", conv_id)\n",
    "    return scenario, plan\n",
    "\n",
    "def make_multiturn_conversation(qa_tuples,logic_llm):\n",
    "    conv_id = make_id()\n",
    "    # thought_plan = create_thought_plan_many_tuples(qa_tuples,character,scenario,logic_llm) # There IS a way to make multiturn chain of thought answering work: generate each pair of messages using a separate prompt or a separate function, each of which has only the thought plan for that question/answer pair. But simply cramming in all the step-by-step things will confuse the hell out of the poor model. So for the pre-alpha, we're skipping it and just giving the response, with no reasoning, in the multiturn convs.\n",
    "    character, instructions = make_multiturn_character(qa_tuples,conv_id)\n",
    "    scenario, scenario_plan = make_multiturn_scenario(qa_tuples, character,conv_id)\n",
    "    conv, conv_output = multi_turn_conversation(qa_tuples, character, scenario, scenario_plan, logic_llm)\n",
    "    write_output_to_file(conv_output, \"./multiturn_conversation_generations\", conv_id)\n",
    "    \n",
    "    return conv \n",
    "\n",
    "\n",
    "\n",
    "def ensure_multiple_answers_are_same(qatuples, conv, scenario): # why is this a whole separate function? Once upon a time, LLMs were used in validation here, too. But programmatic validation SEEMS to catch the common problems. This is here so that I can add it back in if I have to.\n",
    "    \"\"\"Loop to ensure that the answer is consistent in the conversation and in the tuple.\"\"\"\n",
    "    retries = 0\n",
    "    c = conv\n",
    "    while retries < 2: # try twice, since multiturn is an expensive operation\n",
    "        \n",
    "        if call_all_processors(c[0],qatuples):  # if programmatic validation passes\n",
    "            return c\n",
    "\n",
    "        retries += 1\n",
    "        if retries >= 2:\n",
    "            return None\n",
    "        # If we're here, majority of relevance checks failed\n",
    "        print(\"----------------\\n\\n\\n\\nRETRYING!!!!\\n\\n\\n\\n----------------\")\n",
    "        retry = make_multiturn_conversation(qatuples, logic_llm)\n",
    "        if retry is not None:  # Note: retry CANNOT actually be None\n",
    "            c = retry\n",
    "        else:\n",
    "            # If we failed to generate a retry, don't waste compute\n",
    "            return None\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "multi_turn_convs_dir = './multi_turn_convs'\n",
    "if not os.path.exists(multi_turn_convs_dir):\n",
    "    os.makedirs(multi_turn_convs_dir)\n",
    "\n",
    "multi_turn_convs = []\n",
    "for idx, group in enumerate(qa_tuples_by_paragraph):\n",
    "    all_permutations = list(itertools.permutations(group))\n",
    "    \n",
    "    sample_size = min(REARRANGEMENTS_TO_TAKE, len(all_permutations))\n",
    "    sampled_permutations = random.sample(all_permutations, sample_size)\n",
    "    \n",
    "    group_convs = []\n",
    "    \n",
    "    for iter, perm in enumerate(sampled_permutations):\n",
    "        file_path = os.path.join(multi_turn_convs_dir, f'conv_{idx}_{iter}.json')\n",
    "        \n",
    "        # Skip if file already exists\n",
    "        if not os.path.exists(file_path):\n",
    "            conv = make_multiturn_conversation(perm, logic_llm)\n",
    "            final_conv = ensure_multiple_answers_are_same(perm, conv, logic_llm)\n",
    "            \n",
    "            if final_conv is not None:\n",
    "                with open(file_path, 'w') as file:\n",
    "                    json.dump(final_conv, file, indent=4)\n",
    "            \n",
    "            group_convs.append(final_conv)\n",
    "        else:\n",
    "            print(f\"Skipped generating {file_path} as it already exists\")\n",
    "    \n",
    "    multi_turn_convs.append(group_convs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since everything was written to files already, technically we're done.\n",
    "# Convert to Axolotl format: TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4976e0179d97dd6d59b1329a76e601e17b789c2571b41c8b57f5fd69821c0dd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
